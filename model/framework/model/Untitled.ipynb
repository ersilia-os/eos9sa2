{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec15556f",
   "metadata": {},
   "source": [
    "### Vectorize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba14a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a0ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed array of 1777 compounds in 82.698416 seconds\n",
      "scripts/vectorize.py:74: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X=np.nan_to_num(np.array(X).astype(np.float))\n"
     ]
    }
   ],
   "source": [
    "!python scripts/vectorize.py --output_core data/drugs_approved_rdkit --descriptor rdkit  data/drugs_approved.smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8d0a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed array of 4987 compounds in 200.955314 seconds\n",
      "scripts/vectorize.py:74: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X=np.nan_to_num(np.array(X).astype(np.float))\n"
     ]
    }
   ],
   "source": [
    "!python scripts/vectorize.py --output_core data/zinc15_nondrugs_sample_rdkit --descriptor rdkit  data/zinc15_nondrugs_sample.smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c23592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ef88705",
   "metadata": {},
   "source": [
    "## Run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af023f7",
   "metadata": {},
   "source": [
    "### Bayesian NN on RDKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57a2b6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-09 02:52:45,029: INFO): Start\n",
      "/home/amna/drugability/data_preprocess.py:29: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return yaml.load(f)\n",
      "2022-11-09 02:52:45,161: INFO): Config file: config_files/rdkit_ae_zinc_bayesian.yaml\n",
      "2022-11-09 02:52:45,162: INFO): Force resample/reload: False   Force resplit: False\n",
      "2022-11-09 02:52:45,162: INFO): weights_are_none False\n",
      "2022-11-09 02:52:45,162: INFO): Validation mode: 5cv_test\n",
      "2022-11-09 02:52:45,162: INFO): output_core: experiments/rdkit_ae_zinc_bayesian\n",
      "2022-11-09 02:52:45,162: INFO): Epochs: 100\n",
      "2022-11-09 02:52:45,163: INFO): Positive scaling:    0.500\n",
      "2022-11-09 02:52:45,163: INFO): Data loaded.\n",
      "== Config ==\n",
      "cross_validation:\n",
      "  checkpoint: experiments/rdkit_ae_zinc_bayesian_splits_chk.pkz\n",
      "  random_state: 123\n",
      "  test_split: 0.1\n",
      "  validation_split: 0.2\n",
      "loader_config:\n",
      "  data_balance: random\n",
      "  data_checkpoint: experiments/rdkit_ae_zinc_bayesian_data_chk.pkz\n",
      "  data_mu: data/zinc15_nondrugs_sample_rdkit_mu.npz\n",
      "  data_std: data/zinc15_nondrugs_sample_rdkit_std.npz\n",
      "  negative_file: data/zinc15_nondrugs_sample_rdkit.npz\n",
      "  non_zero_idx: data/zinc15_nondrugs_sample_rdkit_idx.npz\n",
      "  positive_file: data/drugs_approved_rdkit.npz\n",
      "model_params:\n",
      "  dropout_flag: true\n",
      "  encoder_hidden_activation: relu\n",
      "  encoder_hidden_units: 90\n",
      "  encoder_num_layers: 1\n",
      "  kind: rdkit_ae\n",
      "  metric_balance: false\n",
      "  model_dropout: 0.2\n",
      "  model_l2: 0.001\n",
      "  num_inputs: 1\n",
      "\n",
      "============\n",
      "2022-11-09 02:52:45,165: INFO): Y shape:(3554, 2)  Y sum:[1777. 1777.]\n",
      "2022-11-09 02:52:45,189: INFO): Train Y: [1279. 1279.]\n",
      "WARNING:tensorflow:From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "2022-11-09 02:52:45,267: WARNING): From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2022-11-09 02:52:45,339: WARNING): From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "2022-11-09 02:52:45.594521: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-11-09 02:52:45.628020: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2419205000 Hz\n",
      "2022-11-09 02:52:45.630551: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x2c145e0 executing computations on platform Host. Devices:\n",
      "2022-11-09 02:52:45.630699: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-11-09 02:52:45,991: INFO): Model build\n",
      "WARNING:tensorflow:From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2022-11-09 02:52:46,279: WARNING): From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 2558 samples, validate on 640 samples\n",
      "Epoch 1/100\n",
      "2558/2558 [==============================] - 1s 431us/step - loss: 0.7817 - categorical_accuracy: 0.6231 - val_loss: 0.5313 - val_categorical_accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "2558/2558 [==============================] - 0s 138us/step - loss: 0.4447 - categorical_accuracy: 0.8303 - val_loss: 0.3775 - val_categorical_accuracy: 0.8547\n",
      "Epoch 3/100\n",
      "2558/2558 [==============================] - 0s 100us/step - loss: 0.3693 - categorical_accuracy: 0.8636 - val_loss: 0.3893 - val_categorical_accuracy: 0.8891\n",
      "Epoch 4/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.3490 - categorical_accuracy: 0.8780 - val_loss: 0.3707 - val_categorical_accuracy: 0.8828\n",
      "Epoch 5/100\n",
      "2558/2558 [==============================] - 0s 149us/step - loss: 0.3282 - categorical_accuracy: 0.8882 - val_loss: 0.3846 - val_categorical_accuracy: 0.8656\n",
      "Epoch 6/100\n",
      "2558/2558 [==============================] - 0s 150us/step - loss: 0.3130 - categorical_accuracy: 0.8956 - val_loss: 0.3501 - val_categorical_accuracy: 0.8703\n",
      "Epoch 7/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.2985 - categorical_accuracy: 0.8991 - val_loss: 0.3562 - val_categorical_accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "2558/2558 [==============================] - 0s 161us/step - loss: 0.2872 - categorical_accuracy: 0.9050 - val_loss: 0.3700 - val_categorical_accuracy: 0.8703\n",
      "Epoch 9/100\n",
      "2558/2558 [==============================] - 0s 172us/step - loss: 0.2840 - categorical_accuracy: 0.9042 - val_loss: 0.3616 - val_categorical_accuracy: 0.8859\n",
      "Epoch 10/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.2804 - categorical_accuracy: 0.9101 - val_loss: 0.3344 - val_categorical_accuracy: 0.8844\n",
      "Epoch 11/100\n",
      "2558/2558 [==============================] - 0s 168us/step - loss: 0.2713 - categorical_accuracy: 0.9144 - val_loss: 0.3494 - val_categorical_accuracy: 0.8891\n",
      "Epoch 12/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2661 - categorical_accuracy: 0.9116 - val_loss: 0.3520 - val_categorical_accuracy: 0.8859\n",
      "Epoch 13/100\n",
      "2558/2558 [==============================] - 1s 202us/step - loss: 0.2695 - categorical_accuracy: 0.9109 - val_loss: 0.3201 - val_categorical_accuracy: 0.8922\n",
      "Epoch 14/100\n",
      "2558/2558 [==============================] - 1s 208us/step - loss: 0.2436 - categorical_accuracy: 0.9292 - val_loss: 0.3173 - val_categorical_accuracy: 0.8984\n",
      "Epoch 15/100\n",
      "2558/2558 [==============================] - 0s 147us/step - loss: 0.2607 - categorical_accuracy: 0.9148 - val_loss: 0.3598 - val_categorical_accuracy: 0.8828\n",
      "Epoch 16/100\n",
      "2558/2558 [==============================] - 0s 167us/step - loss: 0.2651 - categorical_accuracy: 0.9167 - val_loss: 0.3290 - val_categorical_accuracy: 0.8906\n",
      "Epoch 17/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.2493 - categorical_accuracy: 0.9199 - val_loss: 0.3479 - val_categorical_accuracy: 0.9000\n",
      "Epoch 18/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2381 - categorical_accuracy: 0.9277 - val_loss: 0.3398 - val_categorical_accuracy: 0.8844\n",
      "Epoch 19/100\n",
      "2558/2558 [==============================] - 0s 165us/step - loss: 0.2392 - categorical_accuracy: 0.9289 - val_loss: 0.3342 - val_categorical_accuracy: 0.8891\n",
      "Epoch 20/100\n",
      "2558/2558 [==============================] - 0s 111us/step - loss: 0.2296 - categorical_accuracy: 0.9304 - val_loss: 0.3366 - val_categorical_accuracy: 0.8750\n",
      "Epoch 21/100\n",
      "2558/2558 [==============================] - 0s 106us/step - loss: 0.2464 - categorical_accuracy: 0.9226 - val_loss: 0.3475 - val_categorical_accuracy: 0.8875\n",
      "Epoch 22/100\n",
      "2558/2558 [==============================] - 0s 112us/step - loss: 0.2395 - categorical_accuracy: 0.9253 - val_loss: 0.3880 - val_categorical_accuracy: 0.8734\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.2254 - categorical_accuracy: 0.9339 - val_loss: 0.3758 - val_categorical_accuracy: 0.8828\n",
      "Epoch 24/100\n",
      "2558/2558 [==============================] - 0s 138us/step - loss: 0.2274 - categorical_accuracy: 0.9292 - val_loss: 0.3761 - val_categorical_accuracy: 0.8906\n",
      "Epoch 25/100\n",
      "2558/2558 [==============================] - 0s 157us/step - loss: 0.2305 - categorical_accuracy: 0.9335 - val_loss: 0.3421 - val_categorical_accuracy: 0.8953\n",
      "Epoch 26/100\n",
      "2558/2558 [==============================] - 0s 153us/step - loss: 0.2282 - categorical_accuracy: 0.9324 - val_loss: 0.3538 - val_categorical_accuracy: 0.8812\n",
      "Epoch 27/100\n",
      "2558/2558 [==============================] - 0s 156us/step - loss: 0.2336 - categorical_accuracy: 0.9281 - val_loss: 0.3653 - val_categorical_accuracy: 0.8781\n",
      "Epoch 28/100\n",
      "2558/2558 [==============================] - 0s 172us/step - loss: 0.2331 - categorical_accuracy: 0.9335 - val_loss: 0.3652 - val_categorical_accuracy: 0.8719\n",
      "Epoch 29/100\n",
      "2558/2558 [==============================] - 1s 206us/step - loss: 0.2263 - categorical_accuracy: 0.9332 - val_loss: 0.3460 - val_categorical_accuracy: 0.8891\n",
      "Epoch 30/100\n",
      "2558/2558 [==============================] - 0s 149us/step - loss: 0.2305 - categorical_accuracy: 0.9308 - val_loss: 0.3246 - val_categorical_accuracy: 0.8922\n",
      "Epoch 31/100\n",
      "2558/2558 [==============================] - 0s 165us/step - loss: 0.2232 - categorical_accuracy: 0.9289 - val_loss: 0.3550 - val_categorical_accuracy: 0.8891\n",
      "Epoch 32/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.2103 - categorical_accuracy: 0.9375 - val_loss: 0.3813 - val_categorical_accuracy: 0.8828\n",
      "Epoch 33/100\n",
      "2558/2558 [==============================] - 0s 183us/step - loss: 0.2076 - categorical_accuracy: 0.9382 - val_loss: 0.3567 - val_categorical_accuracy: 0.8812\n",
      "Epoch 34/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.2146 - categorical_accuracy: 0.9347 - val_loss: 0.3517 - val_categorical_accuracy: 0.8891\n",
      "Epoch 35/100\n",
      "2558/2558 [==============================] - 0s 120us/step - loss: 0.2068 - categorical_accuracy: 0.9418 - val_loss: 0.3702 - val_categorical_accuracy: 0.8922\n",
      "Epoch 36/100\n",
      "2558/2558 [==============================] - 0s 116us/step - loss: 0.2108 - categorical_accuracy: 0.9378 - val_loss: 0.3625 - val_categorical_accuracy: 0.8906\n",
      "Epoch 37/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.2196 - categorical_accuracy: 0.9312 - val_loss: 0.3489 - val_categorical_accuracy: 0.8859\n",
      "Epoch 38/100\n",
      "2558/2558 [==============================] - 0s 193us/step - loss: 0.2158 - categorical_accuracy: 0.9367 - val_loss: 0.3584 - val_categorical_accuracy: 0.9000\n",
      "Epoch 39/100\n",
      "2558/2558 [==============================] - 0s 125us/step - loss: 0.2036 - categorical_accuracy: 0.9402 - val_loss: 0.3599 - val_categorical_accuracy: 0.8922\n",
      "Epoch 40/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.2094 - categorical_accuracy: 0.9418 - val_loss: 0.3644 - val_categorical_accuracy: 0.8844\n",
      "Epoch 41/100\n",
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.2102 - categorical_accuracy: 0.9351 - val_loss: 0.3608 - val_categorical_accuracy: 0.8891\n",
      "Epoch 42/100\n",
      "2558/2558 [==============================] - 0s 112us/step - loss: 0.2104 - categorical_accuracy: 0.9449 - val_loss: 0.3575 - val_categorical_accuracy: 0.8859\n",
      "Epoch 43/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.2099 - categorical_accuracy: 0.9425 - val_loss: 0.3707 - val_categorical_accuracy: 0.8688\n",
      "Epoch 44/100\n",
      "2558/2558 [==============================] - 0s 116us/step - loss: 0.2071 - categorical_accuracy: 0.9394 - val_loss: 0.3566 - val_categorical_accuracy: 0.8812\n",
      "Epoch 45/100\n",
      "2558/2558 [==============================] - 0s 150us/step - loss: 0.1970 - categorical_accuracy: 0.9457 - val_loss: 0.3684 - val_categorical_accuracy: 0.8953\n",
      "Epoch 46/100\n",
      "2558/2558 [==============================] - 0s 185us/step - loss: 0.1934 - categorical_accuracy: 0.9457 - val_loss: 0.3831 - val_categorical_accuracy: 0.8766\n",
      "Epoch 47/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.2023 - categorical_accuracy: 0.9414 - val_loss: 0.3584 - val_categorical_accuracy: 0.8766\n",
      "Epoch 48/100\n",
      "2558/2558 [==============================] - 0s 169us/step - loss: 0.2043 - categorical_accuracy: 0.9386 - val_loss: 0.3575 - val_categorical_accuracy: 0.8937\n",
      "Epoch 49/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1928 - categorical_accuracy: 0.9468 - val_loss: 0.3818 - val_categorical_accuracy: 0.8875\n",
      "Epoch 50/100\n",
      "2558/2558 [==============================] - 0s 107us/step - loss: 0.2010 - categorical_accuracy: 0.9445 - val_loss: 0.4125 - val_categorical_accuracy: 0.8719\n",
      "Epoch 51/100\n",
      "2558/2558 [==============================] - 0s 130us/step - loss: 0.2050 - categorical_accuracy: 0.9390 - val_loss: 0.3821 - val_categorical_accuracy: 0.8688\n",
      "Epoch 52/100\n",
      "2558/2558 [==============================] - 0s 149us/step - loss: 0.2028 - categorical_accuracy: 0.9375 - val_loss: 0.3899 - val_categorical_accuracy: 0.8734\n",
      "Epoch 53/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.2046 - categorical_accuracy: 0.9425 - val_loss: 0.3708 - val_categorical_accuracy: 0.8844\n",
      "Epoch 54/100\n",
      "2558/2558 [==============================] - 0s 116us/step - loss: 0.1852 - categorical_accuracy: 0.9531 - val_loss: 0.3821 - val_categorical_accuracy: 0.8953\n",
      "Epoch 55/100\n",
      "2558/2558 [==============================] - 0s 102us/step - loss: 0.1987 - categorical_accuracy: 0.9484 - val_loss: 0.4061 - val_categorical_accuracy: 0.8734\n",
      "Epoch 56/100\n",
      "2558/2558 [==============================] - 0s 153us/step - loss: 0.1961 - categorical_accuracy: 0.9425 - val_loss: 0.3723 - val_categorical_accuracy: 0.8828\n",
      "Epoch 57/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.1956 - categorical_accuracy: 0.9461 - val_loss: 0.3748 - val_categorical_accuracy: 0.8859\n",
      "Epoch 58/100\n",
      "2558/2558 [==============================] - 0s 113us/step - loss: 0.1904 - categorical_accuracy: 0.9488 - val_loss: 0.3420 - val_categorical_accuracy: 0.8859\n",
      "Epoch 59/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1935 - categorical_accuracy: 0.9453 - val_loss: 0.3283 - val_categorical_accuracy: 0.9000\n",
      "Epoch 60/100\n",
      "2558/2558 [==============================] - 1s 211us/step - loss: 0.1999 - categorical_accuracy: 0.9488 - val_loss: 0.3869 - val_categorical_accuracy: 0.8828\n",
      "Epoch 61/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.1900 - categorical_accuracy: 0.9453 - val_loss: 0.3881 - val_categorical_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.1914 - categorical_accuracy: 0.9500 - val_loss: 0.3933 - val_categorical_accuracy: 0.8812\n",
      "Epoch 63/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.2012 - categorical_accuracy: 0.9375 - val_loss: 0.3241 - val_categorical_accuracy: 0.9047\n",
      "Epoch 64/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2106 - categorical_accuracy: 0.9402 - val_loss: 0.4102 - val_categorical_accuracy: 0.8703\n",
      "Epoch 65/100\n",
      "2558/2558 [==============================] - 0s 99us/step - loss: 0.1971 - categorical_accuracy: 0.9433 - val_loss: 0.3712 - val_categorical_accuracy: 0.8734\n",
      "Epoch 66/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1913 - categorical_accuracy: 0.9445 - val_loss: 0.3727 - val_categorical_accuracy: 0.8891\n",
      "Epoch 67/100\n",
      "2558/2558 [==============================] - 0s 127us/step - loss: 0.1801 - categorical_accuracy: 0.9531 - val_loss: 0.3916 - val_categorical_accuracy: 0.8688\n",
      "Epoch 68/100\n",
      "2558/2558 [==============================] - 0s 121us/step - loss: 0.1833 - categorical_accuracy: 0.9515 - val_loss: 0.4040 - val_categorical_accuracy: 0.8750\n",
      "Epoch 69/100\n",
      "2558/2558 [==============================] - 0s 157us/step - loss: 0.1921 - categorical_accuracy: 0.9515 - val_loss: 0.3431 - val_categorical_accuracy: 0.8937\n",
      "Epoch 70/100\n",
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.1947 - categorical_accuracy: 0.9445 - val_loss: 0.3937 - val_categorical_accuracy: 0.8812\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 121us/step - loss: 0.1904 - categorical_accuracy: 0.9511 - val_loss: 0.3914 - val_categorical_accuracy: 0.8938\n",
      "Epoch 72/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.1940 - categorical_accuracy: 0.9476 - val_loss: 0.4425 - val_categorical_accuracy: 0.8719\n",
      "Epoch 73/100\n",
      "2558/2558 [==============================] - 0s 118us/step - loss: 0.1815 - categorical_accuracy: 0.9539 - val_loss: 0.3444 - val_categorical_accuracy: 0.8922\n",
      "Epoch 74/100\n",
      "2558/2558 [==============================] - 0s 189us/step - loss: 0.1803 - categorical_accuracy: 0.9480 - val_loss: 0.3651 - val_categorical_accuracy: 0.8844\n",
      "Epoch 75/100\n",
      "2558/2558 [==============================] - 0s 160us/step - loss: 0.1844 - categorical_accuracy: 0.9496 - val_loss: 0.3807 - val_categorical_accuracy: 0.8859\n",
      "Epoch 76/100\n",
      "2558/2558 [==============================] - 0s 154us/step - loss: 0.1905 - categorical_accuracy: 0.9453 - val_loss: 0.4175 - val_categorical_accuracy: 0.8609\n",
      "Epoch 77/100\n",
      "2558/2558 [==============================] - 0s 162us/step - loss: 0.1870 - categorical_accuracy: 0.9496 - val_loss: 0.3787 - val_categorical_accuracy: 0.8813\n",
      "Epoch 78/100\n",
      "2558/2558 [==============================] - 0s 112us/step - loss: 0.1852 - categorical_accuracy: 0.9480 - val_loss: 0.4037 - val_categorical_accuracy: 0.8625\n",
      "Epoch 79/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.1827 - categorical_accuracy: 0.9550 - val_loss: 0.3876 - val_categorical_accuracy: 0.8844\n",
      "Epoch 80/100\n",
      "2558/2558 [==============================] - 0s 111us/step - loss: 0.1819 - categorical_accuracy: 0.9531 - val_loss: 0.4185 - val_categorical_accuracy: 0.8703\n",
      "Epoch 81/100\n",
      "2558/2558 [==============================] - 0s 92us/step - loss: 0.1902 - categorical_accuracy: 0.9468 - val_loss: 0.4094 - val_categorical_accuracy: 0.8828\n",
      "Epoch 82/100\n",
      "2558/2558 [==============================] - 0s 108us/step - loss: 0.1888 - categorical_accuracy: 0.9492 - val_loss: 0.4182 - val_categorical_accuracy: 0.8625\n",
      "Epoch 83/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1772 - categorical_accuracy: 0.9547 - val_loss: 0.4335 - val_categorical_accuracy: 0.8703\n",
      "Epoch 84/100\n",
      "2558/2558 [==============================] - 0s 108us/step - loss: 0.1839 - categorical_accuracy: 0.9507 - val_loss: 0.3989 - val_categorical_accuracy: 0.8812\n",
      "Epoch 85/100\n",
      "2558/2558 [==============================] - 0s 98us/step - loss: 0.1833 - categorical_accuracy: 0.9539 - val_loss: 0.3928 - val_categorical_accuracy: 0.8750\n",
      "Epoch 86/100\n",
      "2558/2558 [==============================] - 0s 96us/step - loss: 0.1808 - categorical_accuracy: 0.9535 - val_loss: 0.3726 - val_categorical_accuracy: 0.8859\n",
      "Epoch 87/100\n",
      "2558/2558 [==============================] - 0s 98us/step - loss: 0.1759 - categorical_accuracy: 0.9558 - val_loss: 0.4364 - val_categorical_accuracy: 0.8844\n",
      "Epoch 88/100\n",
      "2558/2558 [==============================] - 0s 125us/step - loss: 0.1825 - categorical_accuracy: 0.9519 - val_loss: 0.3640 - val_categorical_accuracy: 0.8844\n",
      "Epoch 89/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.1826 - categorical_accuracy: 0.9488 - val_loss: 0.4113 - val_categorical_accuracy: 0.8797\n",
      "Epoch 90/100\n",
      "2558/2558 [==============================] - 0s 170us/step - loss: 0.1823 - categorical_accuracy: 0.9531 - val_loss: 0.4254 - val_categorical_accuracy: 0.8812\n",
      "Epoch 91/100\n",
      "2558/2558 [==============================] - 0s 157us/step - loss: 0.1745 - categorical_accuracy: 0.9543 - val_loss: 0.4097 - val_categorical_accuracy: 0.8688\n",
      "Epoch 92/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1721 - categorical_accuracy: 0.9558 - val_loss: 0.3878 - val_categorical_accuracy: 0.8797\n",
      "Epoch 93/100\n",
      "2558/2558 [==============================] - 0s 163us/step - loss: 0.1810 - categorical_accuracy: 0.9547 - val_loss: 0.4020 - val_categorical_accuracy: 0.8875\n",
      "Epoch 94/100\n",
      "2558/2558 [==============================] - 0s 115us/step - loss: 0.1717 - categorical_accuracy: 0.9523 - val_loss: 0.4442 - val_categorical_accuracy: 0.8578\n",
      "Epoch 95/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1703 - categorical_accuracy: 0.9531 - val_loss: 0.4186 - val_categorical_accuracy: 0.8969\n",
      "Epoch 96/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.1782 - categorical_accuracy: 0.9527 - val_loss: 0.4175 - val_categorical_accuracy: 0.8875\n",
      "Epoch 97/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.1764 - categorical_accuracy: 0.9539 - val_loss: 0.3770 - val_categorical_accuracy: 0.8906\n",
      "Epoch 98/100\n",
      "2558/2558 [==============================] - 0s 138us/step - loss: 0.1830 - categorical_accuracy: 0.9488 - val_loss: 0.4188 - val_categorical_accuracy: 0.8766\n",
      "Epoch 99/100\n",
      "2558/2558 [==============================] - 0s 167us/step - loss: 0.1775 - categorical_accuracy: 0.9527 - val_loss: 0.4301 - val_categorical_accuracy: 0.8828\n",
      "Epoch 100/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.1684 - categorical_accuracy: 0.9574 - val_loss: 0.4123 - val_categorical_accuracy: 0.8687\n",
      "2022-11-09 02:53:23,871: INFO): Train Y: [1279. 1279.]\n",
      "2022-11-09 02:53:24,411: INFO): Model build\n",
      "Train on 2558 samples, validate on 640 samples\n",
      "Epoch 1/100\n",
      "2558/2558 [==============================] - 1s 500us/step - loss: 0.5419 - categorical_accuracy: 0.7604 - val_loss: 0.3743 - val_categorical_accuracy: 0.8563\n",
      "Epoch 2/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.3760 - categorical_accuracy: 0.8636 - val_loss: 0.3447 - val_categorical_accuracy: 0.8781\n",
      "Epoch 3/100\n",
      "2558/2558 [==============================] - 0s 121us/step - loss: 0.3185 - categorical_accuracy: 0.8890 - val_loss: 0.3108 - val_categorical_accuracy: 0.8969\n",
      "Epoch 4/100\n",
      "2558/2558 [==============================] - 0s 127us/step - loss: 0.3078 - categorical_accuracy: 0.8991 - val_loss: 0.2954 - val_categorical_accuracy: 0.9063\n",
      "Epoch 5/100\n",
      "2558/2558 [==============================] - 1s 204us/step - loss: 0.2898 - categorical_accuracy: 0.9085 - val_loss: 0.2993 - val_categorical_accuracy: 0.9000\n",
      "Epoch 6/100\n",
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.2753 - categorical_accuracy: 0.9113 - val_loss: 0.2898 - val_categorical_accuracy: 0.9094\n",
      "Epoch 7/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2651 - categorical_accuracy: 0.9210 - val_loss: 0.3076 - val_categorical_accuracy: 0.8734\n",
      "Epoch 8/100\n",
      "2558/2558 [==============================] - 0s 119us/step - loss: 0.2683 - categorical_accuracy: 0.9132 - val_loss: 0.3017 - val_categorical_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "2558/2558 [==============================] - 0s 112us/step - loss: 0.2491 - categorical_accuracy: 0.9238 - val_loss: 0.3119 - val_categorical_accuracy: 0.8937\n",
      "Epoch 10/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.2473 - categorical_accuracy: 0.9257 - val_loss: 0.3091 - val_categorical_accuracy: 0.8984\n",
      "Epoch 11/100\n",
      "2558/2558 [==============================] - 0s 161us/step - loss: 0.2495 - categorical_accuracy: 0.9289 - val_loss: 0.2974 - val_categorical_accuracy: 0.9156\n",
      "Epoch 12/100\n",
      "2558/2558 [==============================] - 0s 160us/step - loss: 0.2410 - categorical_accuracy: 0.9296 - val_loss: 0.3103 - val_categorical_accuracy: 0.8938\n",
      "Epoch 13/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.2308 - categorical_accuracy: 0.9273 - val_loss: 0.3032 - val_categorical_accuracy: 0.8906\n",
      "Epoch 14/100\n",
      "2558/2558 [==============================] - 0s 115us/step - loss: 0.2249 - categorical_accuracy: 0.9316 - val_loss: 0.2972 - val_categorical_accuracy: 0.9062\n",
      "Epoch 15/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2386 - categorical_accuracy: 0.9292 - val_loss: 0.3146 - val_categorical_accuracy: 0.9000\n",
      "Epoch 16/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.2283 - categorical_accuracy: 0.9324 - val_loss: 0.3137 - val_categorical_accuracy: 0.8969\n",
      "Epoch 17/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.2268 - categorical_accuracy: 0.9355 - val_loss: 0.3071 - val_categorical_accuracy: 0.8906\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 103us/step - loss: 0.2248 - categorical_accuracy: 0.9347 - val_loss: 0.3204 - val_categorical_accuracy: 0.8938\n",
      "Epoch 19/100\n",
      "2558/2558 [==============================] - 0s 127us/step - loss: 0.2195 - categorical_accuracy: 0.9386 - val_loss: 0.3320 - val_categorical_accuracy: 0.8891\n",
      "Epoch 20/100\n",
      "2558/2558 [==============================] - 0s 103us/step - loss: 0.2124 - categorical_accuracy: 0.9402 - val_loss: 0.3111 - val_categorical_accuracy: 0.8953\n",
      "Epoch 21/100\n",
      "2558/2558 [==============================] - 0s 93us/step - loss: 0.2148 - categorical_accuracy: 0.9367 - val_loss: 0.2915 - val_categorical_accuracy: 0.9031\n",
      "Epoch 22/100\n",
      "2558/2558 [==============================] - 0s 103us/step - loss: 0.2251 - categorical_accuracy: 0.9277 - val_loss: 0.3076 - val_categorical_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.2147 - categorical_accuracy: 0.9386 - val_loss: 0.3239 - val_categorical_accuracy: 0.8844\n",
      "Epoch 24/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.2117 - categorical_accuracy: 0.9359 - val_loss: 0.3156 - val_categorical_accuracy: 0.8984\n",
      "Epoch 25/100\n",
      "2558/2558 [==============================] - 0s 127us/step - loss: 0.2078 - categorical_accuracy: 0.9414 - val_loss: 0.3017 - val_categorical_accuracy: 0.8969\n",
      "Epoch 26/100\n",
      "2558/2558 [==============================] - 0s 123us/step - loss: 0.2044 - categorical_accuracy: 0.9449 - val_loss: 0.3270 - val_categorical_accuracy: 0.9000\n",
      "Epoch 27/100\n",
      "2558/2558 [==============================] - 0s 191us/step - loss: 0.2080 - categorical_accuracy: 0.9367 - val_loss: 0.3306 - val_categorical_accuracy: 0.8813\n",
      "Epoch 28/100\n",
      "2558/2558 [==============================] - 0s 159us/step - loss: 0.1996 - categorical_accuracy: 0.9449 - val_loss: 0.3142 - val_categorical_accuracy: 0.8875\n",
      "Epoch 29/100\n",
      "2558/2558 [==============================] - 0s 170us/step - loss: 0.2051 - categorical_accuracy: 0.9371 - val_loss: 0.3234 - val_categorical_accuracy: 0.8922\n",
      "Epoch 30/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.2066 - categorical_accuracy: 0.9414 - val_loss: 0.3400 - val_categorical_accuracy: 0.8953\n",
      "Epoch 31/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2074 - categorical_accuracy: 0.9371 - val_loss: 0.3216 - val_categorical_accuracy: 0.8906\n",
      "Epoch 32/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.1915 - categorical_accuracy: 0.9488 - val_loss: 0.3364 - val_categorical_accuracy: 0.8812\n",
      "Epoch 33/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.2079 - categorical_accuracy: 0.9414 - val_loss: 0.3553 - val_categorical_accuracy: 0.8766\n",
      "Epoch 34/100\n",
      "2558/2558 [==============================] - 0s 167us/step - loss: 0.2006 - categorical_accuracy: 0.9433 - val_loss: 0.3123 - val_categorical_accuracy: 0.8953\n",
      "Epoch 35/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.2033 - categorical_accuracy: 0.9429 - val_loss: 0.3445 - val_categorical_accuracy: 0.8797\n",
      "Epoch 36/100\n",
      "2558/2558 [==============================] - 0s 161us/step - loss: 0.1971 - categorical_accuracy: 0.9461 - val_loss: 0.3273 - val_categorical_accuracy: 0.8828\n",
      "Epoch 37/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.1928 - categorical_accuracy: 0.9488 - val_loss: 0.3499 - val_categorical_accuracy: 0.8734\n",
      "Epoch 38/100\n",
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.1994 - categorical_accuracy: 0.9468 - val_loss: 0.3461 - val_categorical_accuracy: 0.8781\n",
      "Epoch 39/100\n",
      "2558/2558 [==============================] - 0s 154us/step - loss: 0.1969 - categorical_accuracy: 0.9484 - val_loss: 0.3234 - val_categorical_accuracy: 0.8906\n",
      "Epoch 40/100\n",
      "2558/2558 [==============================] - 0s 174us/step - loss: 0.1897 - categorical_accuracy: 0.9496 - val_loss: 0.3587 - val_categorical_accuracy: 0.8859\n",
      "Epoch 41/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.1929 - categorical_accuracy: 0.9480 - val_loss: 0.3743 - val_categorical_accuracy: 0.8766\n",
      "Epoch 42/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.1933 - categorical_accuracy: 0.9461 - val_loss: 0.3357 - val_categorical_accuracy: 0.8922\n",
      "Epoch 43/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.1924 - categorical_accuracy: 0.9437 - val_loss: 0.3294 - val_categorical_accuracy: 0.8859\n",
      "Epoch 44/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.1883 - categorical_accuracy: 0.9476 - val_loss: 0.3280 - val_categorical_accuracy: 0.8922\n",
      "Epoch 45/100\n",
      "2558/2558 [==============================] - 0s 194us/step - loss: 0.1922 - categorical_accuracy: 0.9464 - val_loss: 0.3566 - val_categorical_accuracy: 0.8828\n",
      "Epoch 46/100\n",
      "2558/2558 [==============================] - 0s 169us/step - loss: 0.1928 - categorical_accuracy: 0.9453 - val_loss: 0.3448 - val_categorical_accuracy: 0.8891\n",
      "Epoch 47/100\n",
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.1865 - categorical_accuracy: 0.9519 - val_loss: 0.3312 - val_categorical_accuracy: 0.8859\n",
      "Epoch 48/100\n",
      "2558/2558 [==============================] - 0s 116us/step - loss: 0.1997 - categorical_accuracy: 0.9378 - val_loss: 0.3630 - val_categorical_accuracy: 0.8859\n",
      "Epoch 49/100\n",
      "2558/2558 [==============================] - 0s 121us/step - loss: 0.1845 - categorical_accuracy: 0.9519 - val_loss: 0.3311 - val_categorical_accuracy: 0.8906\n",
      "Epoch 50/100\n",
      "2558/2558 [==============================] - 0s 115us/step - loss: 0.1848 - categorical_accuracy: 0.9484 - val_loss: 0.3831 - val_categorical_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "2558/2558 [==============================] - 0s 114us/step - loss: 0.1894 - categorical_accuracy: 0.9488 - val_loss: 0.3427 - val_categorical_accuracy: 0.8797\n",
      "Epoch 52/100\n",
      "2558/2558 [==============================] - 0s 116us/step - loss: 0.1830 - categorical_accuracy: 0.9511 - val_loss: 0.3834 - val_categorical_accuracy: 0.8859\n",
      "Epoch 53/100\n",
      "2558/2558 [==============================] - 0s 123us/step - loss: 0.1797 - categorical_accuracy: 0.9531 - val_loss: 0.3370 - val_categorical_accuracy: 0.8859\n",
      "Epoch 54/100\n",
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.1826 - categorical_accuracy: 0.9535 - val_loss: 0.3476 - val_categorical_accuracy: 0.8797\n",
      "Epoch 55/100\n",
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.1916 - categorical_accuracy: 0.9511 - val_loss: 0.3923 - val_categorical_accuracy: 0.8797\n",
      "Epoch 56/100\n",
      "2558/2558 [==============================] - 0s 194us/step - loss: 0.1814 - categorical_accuracy: 0.9441 - val_loss: 0.3529 - val_categorical_accuracy: 0.8797\n",
      "Epoch 57/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.1907 - categorical_accuracy: 0.9457 - val_loss: 0.3618 - val_categorical_accuracy: 0.8891\n",
      "Epoch 58/100\n",
      "2558/2558 [==============================] - 0s 155us/step - loss: 0.1927 - categorical_accuracy: 0.9433 - val_loss: 0.3794 - val_categorical_accuracy: 0.8594\n",
      "Epoch 59/100\n",
      "2558/2558 [==============================] - 0s 166us/step - loss: 0.1769 - categorical_accuracy: 0.9535 - val_loss: 0.3955 - val_categorical_accuracy: 0.8828\n",
      "Epoch 60/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1822 - categorical_accuracy: 0.9492 - val_loss: 0.3429 - val_categorical_accuracy: 0.8828\n",
      "Epoch 61/100\n",
      "2558/2558 [==============================] - 0s 140us/step - loss: 0.1758 - categorical_accuracy: 0.9535 - val_loss: 0.4157 - val_categorical_accuracy: 0.8578\n",
      "Epoch 62/100\n",
      "2558/2558 [==============================] - 0s 145us/step - loss: 0.1828 - categorical_accuracy: 0.9488 - val_loss: 0.4143 - val_categorical_accuracy: 0.8781\n",
      "Epoch 63/100\n",
      "2558/2558 [==============================] - 0s 118us/step - loss: 0.1710 - categorical_accuracy: 0.9535 - val_loss: 0.3911 - val_categorical_accuracy: 0.8844\n",
      "Epoch 64/100\n",
      "2558/2558 [==============================] - 0s 110us/step - loss: 0.1746 - categorical_accuracy: 0.9609 - val_loss: 0.4015 - val_categorical_accuracy: 0.8719\n",
      "Epoch 65/100\n",
      "2558/2558 [==============================] - 0s 123us/step - loss: 0.1868 - categorical_accuracy: 0.9527 - val_loss: 0.4084 - val_categorical_accuracy: 0.8625\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 119us/step - loss: 0.1808 - categorical_accuracy: 0.9523 - val_loss: 0.3964 - val_categorical_accuracy: 0.8828\n",
      "Epoch 67/100\n",
      "2558/2558 [==============================] - 0s 105us/step - loss: 0.1938 - categorical_accuracy: 0.9457 - val_loss: 0.4230 - val_categorical_accuracy: 0.8766\n",
      "Epoch 68/100\n",
      "2558/2558 [==============================] - 0s 147us/step - loss: 0.1741 - categorical_accuracy: 0.9566 - val_loss: 0.4184 - val_categorical_accuracy: 0.8734\n",
      "Epoch 69/100\n",
      "2558/2558 [==============================] - 0s 175us/step - loss: 0.1840 - categorical_accuracy: 0.9527 - val_loss: 0.4025 - val_categorical_accuracy: 0.8703\n",
      "Epoch 70/100\n",
      "2558/2558 [==============================] - 0s 166us/step - loss: 0.1760 - categorical_accuracy: 0.9543 - val_loss: 0.4076 - val_categorical_accuracy: 0.8703\n",
      "Epoch 71/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.1764 - categorical_accuracy: 0.9527 - val_loss: 0.3931 - val_categorical_accuracy: 0.8781\n",
      "Epoch 72/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.1745 - categorical_accuracy: 0.9507 - val_loss: 0.3927 - val_categorical_accuracy: 0.8656\n",
      "Epoch 73/100\n",
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.1782 - categorical_accuracy: 0.9531 - val_loss: 0.3890 - val_categorical_accuracy: 0.8766\n",
      "Epoch 74/100\n",
      "2558/2558 [==============================] - 0s 158us/step - loss: 0.1811 - categorical_accuracy: 0.9554 - val_loss: 0.4450 - val_categorical_accuracy: 0.8609\n",
      "Epoch 75/100\n",
      "2558/2558 [==============================] - 0s 155us/step - loss: 0.1850 - categorical_accuracy: 0.9480 - val_loss: 0.3527 - val_categorical_accuracy: 0.8922\n",
      "Epoch 76/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.1636 - categorical_accuracy: 0.9586 - val_loss: 0.4181 - val_categorical_accuracy: 0.8688\n",
      "Epoch 77/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1796 - categorical_accuracy: 0.9554 - val_loss: 0.3750 - val_categorical_accuracy: 0.8828\n",
      "Epoch 78/100\n",
      "2558/2558 [==============================] - 0s 109us/step - loss: 0.1706 - categorical_accuracy: 0.9582 - val_loss: 0.3962 - val_categorical_accuracy: 0.8766\n",
      "Epoch 79/100\n",
      "2558/2558 [==============================] - 0s 115us/step - loss: 0.1780 - categorical_accuracy: 0.9496 - val_loss: 0.3965 - val_categorical_accuracy: 0.8781\n",
      "Epoch 80/100\n",
      "2558/2558 [==============================] - 0s 122us/step - loss: 0.1692 - categorical_accuracy: 0.9586 - val_loss: 0.3784 - val_categorical_accuracy: 0.8766\n",
      "Epoch 81/100\n",
      "2558/2558 [==============================] - 0s 93us/step - loss: 0.1791 - categorical_accuracy: 0.9535 - val_loss: 0.3681 - val_categorical_accuracy: 0.8984\n",
      "Epoch 82/100\n",
      "2558/2558 [==============================] - 0s 102us/step - loss: 0.1748 - categorical_accuracy: 0.9597 - val_loss: 0.4086 - val_categorical_accuracy: 0.8562\n",
      "Epoch 83/100\n",
      "2558/2558 [==============================] - 0s 90us/step - loss: 0.1788 - categorical_accuracy: 0.9574 - val_loss: 0.4305 - val_categorical_accuracy: 0.8656\n",
      "Epoch 84/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.1703 - categorical_accuracy: 0.9550 - val_loss: 0.4140 - val_categorical_accuracy: 0.8594\n",
      "Epoch 85/100\n",
      "2558/2558 [==============================] - 0s 157us/step - loss: 0.1600 - categorical_accuracy: 0.9586 - val_loss: 0.3925 - val_categorical_accuracy: 0.8813\n",
      "Epoch 86/100\n",
      "2558/2558 [==============================] - 0s 120us/step - loss: 0.1673 - categorical_accuracy: 0.9574 - val_loss: 0.4130 - val_categorical_accuracy: 0.8688\n",
      "Epoch 87/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.1766 - categorical_accuracy: 0.9523 - val_loss: 0.4253 - val_categorical_accuracy: 0.8797\n",
      "Epoch 88/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.1838 - categorical_accuracy: 0.9539 - val_loss: 0.3846 - val_categorical_accuracy: 0.8859\n",
      "Epoch 89/100\n",
      "2558/2558 [==============================] - 0s 153us/step - loss: 0.1810 - categorical_accuracy: 0.9543 - val_loss: 0.3766 - val_categorical_accuracy: 0.8766\n",
      "Epoch 90/100\n",
      "2558/2558 [==============================] - 0s 138us/step - loss: 0.1748 - categorical_accuracy: 0.9582 - val_loss: 0.3817 - val_categorical_accuracy: 0.8781\n",
      "Epoch 91/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.1749 - categorical_accuracy: 0.9566 - val_loss: 0.4309 - val_categorical_accuracy: 0.8766\n",
      "Epoch 92/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1716 - categorical_accuracy: 0.9601 - val_loss: 0.4292 - val_categorical_accuracy: 0.8562\n",
      "Epoch 93/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.1753 - categorical_accuracy: 0.9554 - val_loss: 0.3852 - val_categorical_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.1650 - categorical_accuracy: 0.9597 - val_loss: 0.3863 - val_categorical_accuracy: 0.8828\n",
      "Epoch 95/100\n",
      "2558/2558 [==============================] - 0s 172us/step - loss: 0.1722 - categorical_accuracy: 0.9547 - val_loss: 0.4016 - val_categorical_accuracy: 0.8859\n",
      "Epoch 96/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1642 - categorical_accuracy: 0.9597 - val_loss: 0.3821 - val_categorical_accuracy: 0.8891\n",
      "Epoch 97/100\n",
      "2558/2558 [==============================] - 0s 165us/step - loss: 0.1758 - categorical_accuracy: 0.9527 - val_loss: 0.3957 - val_categorical_accuracy: 0.8813\n",
      "Epoch 98/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.1739 - categorical_accuracy: 0.9504 - val_loss: 0.4102 - val_categorical_accuracy: 0.8766\n",
      "Epoch 99/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1580 - categorical_accuracy: 0.9664 - val_loss: 0.4071 - val_categorical_accuracy: 0.8594\n",
      "Epoch 100/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.1669 - categorical_accuracy: 0.9597 - val_loss: 0.4181 - val_categorical_accuracy: 0.8797\n",
      "2022-11-09 02:54:02,104: INFO): Train Y: [1279. 1279.]\n",
      "2022-11-09 02:54:02,664: INFO): Model build\n",
      "Train on 2558 samples, validate on 640 samples\n",
      "Epoch 1/100\n",
      "2558/2558 [==============================] - 1s 468us/step - loss: 0.7370 - categorical_accuracy: 0.7201 - val_loss: 0.5487 - val_categorical_accuracy: 0.7969\n",
      "Epoch 2/100\n",
      "2558/2558 [==============================] - 0s 116us/step - loss: 0.4137 - categorical_accuracy: 0.8581 - val_loss: 0.4280 - val_categorical_accuracy: 0.8312\n",
      "Epoch 3/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.3405 - categorical_accuracy: 0.8808 - val_loss: 0.3732 - val_categorical_accuracy: 0.8656\n",
      "Epoch 4/100\n",
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.3230 - categorical_accuracy: 0.8933 - val_loss: 0.3821 - val_categorical_accuracy: 0.8656\n",
      "Epoch 5/100\n",
      "2558/2558 [==============================] - 0s 102us/step - loss: 0.2965 - categorical_accuracy: 0.8968 - val_loss: 0.3709 - val_categorical_accuracy: 0.8578\n",
      "Epoch 6/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2837 - categorical_accuracy: 0.9070 - val_loss: 0.3551 - val_categorical_accuracy: 0.8734\n",
      "Epoch 7/100\n",
      "2558/2558 [==============================] - 0s 107us/step - loss: 0.2751 - categorical_accuracy: 0.9152 - val_loss: 0.3565 - val_categorical_accuracy: 0.8531\n",
      "Epoch 8/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2641 - categorical_accuracy: 0.9116 - val_loss: 0.3431 - val_categorical_accuracy: 0.8813\n",
      "Epoch 9/100\n",
      "2558/2558 [==============================] - 0s 155us/step - loss: 0.2542 - categorical_accuracy: 0.9206 - val_loss: 0.3389 - val_categorical_accuracy: 0.8703\n",
      "Epoch 10/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.2502 - categorical_accuracy: 0.9187 - val_loss: 0.3606 - val_categorical_accuracy: 0.8719\n",
      "Epoch 11/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2413 - categorical_accuracy: 0.9296 - val_loss: 0.3362 - val_categorical_accuracy: 0.8641\n",
      "Epoch 12/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.2451 - categorical_accuracy: 0.9312 - val_loss: 0.3369 - val_categorical_accuracy: 0.8766\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.2389 - categorical_accuracy: 0.9328 - val_loss: 0.3524 - val_categorical_accuracy: 0.8703\n",
      "Epoch 14/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2512 - categorical_accuracy: 0.9187 - val_loss: 0.3787 - val_categorical_accuracy: 0.8594\n",
      "Epoch 15/100\n",
      "2558/2558 [==============================] - 0s 157us/step - loss: 0.2451 - categorical_accuracy: 0.9206 - val_loss: 0.3256 - val_categorical_accuracy: 0.8766\n",
      "Epoch 16/100\n",
      "2558/2558 [==============================] - 0s 130us/step - loss: 0.2218 - categorical_accuracy: 0.9414 - val_loss: 0.3619 - val_categorical_accuracy: 0.8781\n",
      "Epoch 17/100\n",
      "2558/2558 [==============================] - 0s 94us/step - loss: 0.2332 - categorical_accuracy: 0.9308 - val_loss: 0.3397 - val_categorical_accuracy: 0.8844\n",
      "Epoch 18/100\n",
      "2558/2558 [==============================] - 0s 71us/step - loss: 0.2175 - categorical_accuracy: 0.9355 - val_loss: 0.3740 - val_categorical_accuracy: 0.8687\n",
      "Epoch 19/100\n",
      "2558/2558 [==============================] - 0s 92us/step - loss: 0.2230 - categorical_accuracy: 0.9300 - val_loss: 0.3299 - val_categorical_accuracy: 0.8828\n",
      "Epoch 20/100\n",
      "2558/2558 [==============================] - 0s 95us/step - loss: 0.2160 - categorical_accuracy: 0.9378 - val_loss: 0.3591 - val_categorical_accuracy: 0.8906\n",
      "Epoch 21/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.2259 - categorical_accuracy: 0.9312 - val_loss: 0.3577 - val_categorical_accuracy: 0.8734\n",
      "Epoch 22/100\n",
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.2217 - categorical_accuracy: 0.9308 - val_loss: 0.3416 - val_categorical_accuracy: 0.8719\n",
      "Epoch 23/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.2128 - categorical_accuracy: 0.9375 - val_loss: 0.3495 - val_categorical_accuracy: 0.8703\n",
      "Epoch 24/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.2228 - categorical_accuracy: 0.9343 - val_loss: 0.3481 - val_categorical_accuracy: 0.8719\n",
      "Epoch 25/100\n",
      "2558/2558 [==============================] - 0s 159us/step - loss: 0.2037 - categorical_accuracy: 0.9425 - val_loss: 0.3503 - val_categorical_accuracy: 0.8750\n",
      "Epoch 26/100\n",
      "2558/2558 [==============================] - 0s 117us/step - loss: 0.2116 - categorical_accuracy: 0.9382 - val_loss: 0.3668 - val_categorical_accuracy: 0.8641\n",
      "Epoch 27/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.2152 - categorical_accuracy: 0.9367 - val_loss: 0.3641 - val_categorical_accuracy: 0.8719\n",
      "Epoch 28/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.2046 - categorical_accuracy: 0.9398 - val_loss: 0.3633 - val_categorical_accuracy: 0.8625\n",
      "Epoch 29/100\n",
      "2558/2558 [==============================] - 0s 108us/step - loss: 0.2072 - categorical_accuracy: 0.9414 - val_loss: 0.3445 - val_categorical_accuracy: 0.8797\n",
      "Epoch 30/100\n",
      "2558/2558 [==============================] - 0s 99us/step - loss: 0.2016 - categorical_accuracy: 0.9414 - val_loss: 0.3477 - val_categorical_accuracy: 0.8781\n",
      "Epoch 31/100\n",
      "2558/2558 [==============================] - 0s 118us/step - loss: 0.2129 - categorical_accuracy: 0.9410 - val_loss: 0.3853 - val_categorical_accuracy: 0.8766\n",
      "Epoch 32/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.2048 - categorical_accuracy: 0.9414 - val_loss: 0.3665 - val_categorical_accuracy: 0.8594\n",
      "Epoch 33/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.2031 - categorical_accuracy: 0.9464 - val_loss: 0.3430 - val_categorical_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "2558/2558 [==============================] - 0s 169us/step - loss: 0.2011 - categorical_accuracy: 0.9421 - val_loss: 0.3478 - val_categorical_accuracy: 0.8797\n",
      "Epoch 35/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.2032 - categorical_accuracy: 0.9464 - val_loss: 0.4109 - val_categorical_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.1977 - categorical_accuracy: 0.9453 - val_loss: 0.3499 - val_categorical_accuracy: 0.8766\n",
      "Epoch 37/100\n",
      "2558/2558 [==============================] - 0s 176us/step - loss: 0.1951 - categorical_accuracy: 0.9468 - val_loss: 0.4042 - val_categorical_accuracy: 0.8562\n",
      "Epoch 38/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1890 - categorical_accuracy: 0.9457 - val_loss: 0.3946 - val_categorical_accuracy: 0.8625\n",
      "Epoch 39/100\n",
      "2558/2558 [==============================] - 0s 174us/step - loss: 0.1804 - categorical_accuracy: 0.9488 - val_loss: 0.3497 - val_categorical_accuracy: 0.8750\n",
      "Epoch 40/100\n",
      "2558/2558 [==============================] - 0s 168us/step - loss: 0.2065 - categorical_accuracy: 0.9406 - val_loss: 0.4168 - val_categorical_accuracy: 0.8562\n",
      "Epoch 41/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.1921 - categorical_accuracy: 0.9421 - val_loss: 0.4406 - val_categorical_accuracy: 0.8437\n",
      "Epoch 42/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1861 - categorical_accuracy: 0.9492 - val_loss: 0.4204 - val_categorical_accuracy: 0.8531\n",
      "Epoch 43/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.1975 - categorical_accuracy: 0.9453 - val_loss: 0.3937 - val_categorical_accuracy: 0.8484\n",
      "Epoch 44/100\n",
      "2558/2558 [==============================] - 0s 147us/step - loss: 0.1949 - categorical_accuracy: 0.9433 - val_loss: 0.3850 - val_categorical_accuracy: 0.8609\n",
      "Epoch 45/100\n",
      "2558/2558 [==============================] - 0s 122us/step - loss: 0.1811 - categorical_accuracy: 0.9515 - val_loss: 0.3952 - val_categorical_accuracy: 0.8500\n",
      "Epoch 46/100\n",
      "2558/2558 [==============================] - 0s 117us/step - loss: 0.1919 - categorical_accuracy: 0.9453 - val_loss: 0.4029 - val_categorical_accuracy: 0.8547\n",
      "Epoch 47/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1856 - categorical_accuracy: 0.9472 - val_loss: 0.4483 - val_categorical_accuracy: 0.8516\n",
      "Epoch 48/100\n",
      "2558/2558 [==============================] - 0s 130us/step - loss: 0.1924 - categorical_accuracy: 0.9429 - val_loss: 0.3923 - val_categorical_accuracy: 0.8578\n",
      "Epoch 49/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1878 - categorical_accuracy: 0.9476 - val_loss: 0.4047 - val_categorical_accuracy: 0.8688\n",
      "Epoch 50/100\n",
      "2558/2558 [==============================] - 0s 145us/step - loss: 0.1844 - categorical_accuracy: 0.9511 - val_loss: 0.3948 - val_categorical_accuracy: 0.8625\n",
      "Epoch 51/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1898 - categorical_accuracy: 0.9484 - val_loss: 0.4176 - val_categorical_accuracy: 0.8656\n",
      "Epoch 52/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.1877 - categorical_accuracy: 0.9433 - val_loss: 0.4293 - val_categorical_accuracy: 0.8516\n",
      "Epoch 53/100\n",
      "2558/2558 [==============================] - 0s 155us/step - loss: 0.1810 - categorical_accuracy: 0.9480 - val_loss: 0.4545 - val_categorical_accuracy: 0.8469\n",
      "Epoch 54/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.1807 - categorical_accuracy: 0.9515 - val_loss: 0.3910 - val_categorical_accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1747 - categorical_accuracy: 0.9578 - val_loss: 0.4169 - val_categorical_accuracy: 0.8406\n",
      "Epoch 56/100\n",
      "2558/2558 [==============================] - 0s 103us/step - loss: 0.1848 - categorical_accuracy: 0.9539 - val_loss: 0.4005 - val_categorical_accuracy: 0.8484\n",
      "Epoch 57/100\n",
      "2558/2558 [==============================] - 0s 142us/step - loss: 0.1792 - categorical_accuracy: 0.9523 - val_loss: 0.3962 - val_categorical_accuracy: 0.8531\n",
      "Epoch 58/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.1812 - categorical_accuracy: 0.9488 - val_loss: 0.4149 - val_categorical_accuracy: 0.8609\n",
      "Epoch 59/100\n",
      "2558/2558 [==============================] - 0s 184us/step - loss: 0.1723 - categorical_accuracy: 0.9586 - val_loss: 0.4350 - val_categorical_accuracy: 0.8656\n",
      "Epoch 60/100\n",
      "2558/2558 [==============================] - 0s 160us/step - loss: 0.1877 - categorical_accuracy: 0.9492 - val_loss: 0.4193 - val_categorical_accuracy: 0.8594\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 186us/step - loss: 0.1824 - categorical_accuracy: 0.9511 - val_loss: 0.3901 - val_categorical_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.1956 - categorical_accuracy: 0.9480 - val_loss: 0.3959 - val_categorical_accuracy: 0.8563\n",
      "Epoch 63/100\n",
      "2558/2558 [==============================] - 0s 111us/step - loss: 0.1800 - categorical_accuracy: 0.9550 - val_loss: 0.4927 - val_categorical_accuracy: 0.8422\n",
      "Epoch 64/100\n",
      "2558/2558 [==============================] - 0s 122us/step - loss: 0.1809 - categorical_accuracy: 0.9511 - val_loss: 0.4241 - val_categorical_accuracy: 0.8625\n",
      "Epoch 65/100\n",
      "2558/2558 [==============================] - 0s 145us/step - loss: 0.1764 - categorical_accuracy: 0.9547 - val_loss: 0.4720 - val_categorical_accuracy: 0.8641\n",
      "Epoch 66/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.1839 - categorical_accuracy: 0.9507 - val_loss: 0.4214 - val_categorical_accuracy: 0.8484\n",
      "Epoch 67/100\n",
      "2558/2558 [==============================] - 0s 154us/step - loss: 0.1717 - categorical_accuracy: 0.9570 - val_loss: 0.4599 - val_categorical_accuracy: 0.8469\n",
      "Epoch 68/100\n",
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.1722 - categorical_accuracy: 0.9566 - val_loss: 0.3908 - val_categorical_accuracy: 0.8672\n",
      "Epoch 69/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.1785 - categorical_accuracy: 0.9539 - val_loss: 0.4492 - val_categorical_accuracy: 0.8453\n",
      "Epoch 70/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.1738 - categorical_accuracy: 0.9562 - val_loss: 0.4591 - val_categorical_accuracy: 0.8547\n",
      "Epoch 71/100\n",
      "2558/2558 [==============================] - 0s 174us/step - loss: 0.1678 - categorical_accuracy: 0.9550 - val_loss: 0.4554 - val_categorical_accuracy: 0.8453\n",
      "Epoch 72/100\n",
      "2558/2558 [==============================] - 0s 132us/step - loss: 0.1669 - categorical_accuracy: 0.9547 - val_loss: 0.4690 - val_categorical_accuracy: 0.8563\n",
      "Epoch 73/100\n",
      "2558/2558 [==============================] - 0s 174us/step - loss: 0.1757 - categorical_accuracy: 0.9554 - val_loss: 0.4871 - val_categorical_accuracy: 0.8484\n",
      "Epoch 74/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.1782 - categorical_accuracy: 0.9527 - val_loss: 0.4295 - val_categorical_accuracy: 0.8484\n",
      "Epoch 75/100\n",
      "2558/2558 [==============================] - 0s 122us/step - loss: 0.1708 - categorical_accuracy: 0.9586 - val_loss: 0.4492 - val_categorical_accuracy: 0.8562\n",
      "Epoch 76/100\n",
      "2558/2558 [==============================] - 0s 111us/step - loss: 0.1674 - categorical_accuracy: 0.9582 - val_loss: 0.4601 - val_categorical_accuracy: 0.8578\n",
      "Epoch 77/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.1752 - categorical_accuracy: 0.9527 - val_loss: 0.4697 - val_categorical_accuracy: 0.8375\n",
      "Epoch 78/100\n",
      "2558/2558 [==============================] - 0s 130us/step - loss: 0.1819 - categorical_accuracy: 0.9519 - val_loss: 0.4322 - val_categorical_accuracy: 0.8547\n",
      "Epoch 79/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1786 - categorical_accuracy: 0.9547 - val_loss: 0.4568 - val_categorical_accuracy: 0.8578\n",
      "Epoch 80/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1648 - categorical_accuracy: 0.9593 - val_loss: 0.4501 - val_categorical_accuracy: 0.8500\n",
      "Epoch 81/100\n",
      "2558/2558 [==============================] - 0s 173us/step - loss: 0.1938 - categorical_accuracy: 0.9507 - val_loss: 0.4592 - val_categorical_accuracy: 0.8500\n",
      "Epoch 82/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.1698 - categorical_accuracy: 0.9527 - val_loss: 0.4768 - val_categorical_accuracy: 0.8469\n",
      "Epoch 83/100\n",
      "2558/2558 [==============================] - 0s 182us/step - loss: 0.1649 - categorical_accuracy: 0.9586 - val_loss: 0.4548 - val_categorical_accuracy: 0.8547\n",
      "Epoch 84/100\n",
      "2558/2558 [==============================] - 0s 174us/step - loss: 0.1641 - categorical_accuracy: 0.9578 - val_loss: 0.4591 - val_categorical_accuracy: 0.8547\n",
      "Epoch 85/100\n",
      "2558/2558 [==============================] - 0s 163us/step - loss: 0.1730 - categorical_accuracy: 0.9539 - val_loss: 0.4596 - val_categorical_accuracy: 0.8625\n",
      "Epoch 86/100\n",
      "2558/2558 [==============================] - 1s 205us/step - loss: 0.1675 - categorical_accuracy: 0.9578 - val_loss: 0.4552 - val_categorical_accuracy: 0.8547\n",
      "Epoch 87/100\n",
      "2558/2558 [==============================] - 1s 210us/step - loss: 0.1639 - categorical_accuracy: 0.9605 - val_loss: 0.4380 - val_categorical_accuracy: 0.8594\n",
      "Epoch 88/100\n",
      "2558/2558 [==============================] - 1s 201us/step - loss: 0.1723 - categorical_accuracy: 0.9613 - val_loss: 0.4187 - val_categorical_accuracy: 0.8703\n",
      "Epoch 89/100\n",
      "2558/2558 [==============================] - 0s 181us/step - loss: 0.1688 - categorical_accuracy: 0.9629 - val_loss: 0.4611 - val_categorical_accuracy: 0.8438\n",
      "Epoch 90/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.1769 - categorical_accuracy: 0.9554 - val_loss: 0.4838 - val_categorical_accuracy: 0.8406\n",
      "Epoch 91/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1725 - categorical_accuracy: 0.9562 - val_loss: 0.5215 - val_categorical_accuracy: 0.8281\n",
      "Epoch 92/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1704 - categorical_accuracy: 0.9554 - val_loss: 0.4375 - val_categorical_accuracy: 0.8516\n",
      "Epoch 93/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.1680 - categorical_accuracy: 0.9543 - val_loss: 0.4266 - val_categorical_accuracy: 0.8625\n",
      "Epoch 94/100\n",
      "2558/2558 [==============================] - 0s 119us/step - loss: 0.1692 - categorical_accuracy: 0.9582 - val_loss: 0.4447 - val_categorical_accuracy: 0.8516\n",
      "Epoch 95/100\n",
      "2558/2558 [==============================] - 0s 154us/step - loss: 0.1665 - categorical_accuracy: 0.9613 - val_loss: 0.4522 - val_categorical_accuracy: 0.8562\n",
      "Epoch 96/100\n",
      "2558/2558 [==============================] - 0s 112us/step - loss: 0.1584 - categorical_accuracy: 0.9625 - val_loss: 0.4696 - val_categorical_accuracy: 0.8469\n",
      "Epoch 97/100\n",
      "2558/2558 [==============================] - 0s 127us/step - loss: 0.1652 - categorical_accuracy: 0.9640 - val_loss: 0.4580 - val_categorical_accuracy: 0.8437\n",
      "Epoch 98/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.1754 - categorical_accuracy: 0.9554 - val_loss: 0.4386 - val_categorical_accuracy: 0.8406\n",
      "Epoch 99/100\n",
      "2558/2558 [==============================] - 0s 154us/step - loss: 0.1674 - categorical_accuracy: 0.9586 - val_loss: 0.4322 - val_categorical_accuracy: 0.8547\n",
      "Epoch 100/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1582 - categorical_accuracy: 0.9597 - val_loss: 0.4444 - val_categorical_accuracy: 0.8578\n",
      "2022-11-09 02:54:40,512: INFO): Train Y: [1279. 1279.]\n",
      "2022-11-09 02:54:41,303: INFO): Model build\n",
      "Train on 2558 samples, validate on 640 samples\n",
      "Epoch 1/100\n",
      "2558/2558 [==============================] - 1s 472us/step - loss: 0.4943 - categorical_accuracy: 0.7967 - val_loss: 0.3789 - val_categorical_accuracy: 0.8844\n",
      "Epoch 2/100\n",
      "2558/2558 [==============================] - 0s 122us/step - loss: 0.3531 - categorical_accuracy: 0.8812 - val_loss: 0.3747 - val_categorical_accuracy: 0.8641\n",
      "Epoch 3/100\n",
      "2558/2558 [==============================] - 0s 119us/step - loss: 0.3224 - categorical_accuracy: 0.8819 - val_loss: 0.3369 - val_categorical_accuracy: 0.8828\n",
      "Epoch 4/100\n",
      "2558/2558 [==============================] - 0s 119us/step - loss: 0.2772 - categorical_accuracy: 0.9101 - val_loss: 0.3595 - val_categorical_accuracy: 0.8609\n",
      "Epoch 5/100\n",
      "2558/2558 [==============================] - 0s 123us/step - loss: 0.2693 - categorical_accuracy: 0.9132 - val_loss: 0.3322 - val_categorical_accuracy: 0.9031\n",
      "Epoch 6/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.2594 - categorical_accuracy: 0.9206 - val_loss: 0.2978 - val_categorical_accuracy: 0.8984\n",
      "Epoch 7/100\n",
      "2558/2558 [==============================] - 0s 140us/step - loss: 0.2572 - categorical_accuracy: 0.9179 - val_loss: 0.3299 - val_categorical_accuracy: 0.8719\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 135us/step - loss: 0.2384 - categorical_accuracy: 0.9289 - val_loss: 0.3398 - val_categorical_accuracy: 0.8766\n",
      "Epoch 9/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.2502 - categorical_accuracy: 0.9210 - val_loss: 0.3375 - val_categorical_accuracy: 0.8891\n",
      "Epoch 10/100\n",
      "2558/2558 [==============================] - 0s 155us/step - loss: 0.2474 - categorical_accuracy: 0.9246 - val_loss: 0.3196 - val_categorical_accuracy: 0.8906\n",
      "Epoch 11/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2361 - categorical_accuracy: 0.9277 - val_loss: 0.3026 - val_categorical_accuracy: 0.8828\n",
      "Epoch 12/100\n",
      "2558/2558 [==============================] - 0s 122us/step - loss: 0.2409 - categorical_accuracy: 0.9265 - val_loss: 0.3366 - val_categorical_accuracy: 0.8984\n",
      "Epoch 13/100\n",
      "2558/2558 [==============================] - 0s 134us/step - loss: 0.2321 - categorical_accuracy: 0.9316 - val_loss: 0.3023 - val_categorical_accuracy: 0.8953\n",
      "Epoch 14/100\n",
      "2558/2558 [==============================] - 0s 117us/step - loss: 0.2269 - categorical_accuracy: 0.9300 - val_loss: 0.3384 - val_categorical_accuracy: 0.8969\n",
      "Epoch 15/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2279 - categorical_accuracy: 0.9328 - val_loss: 0.3416 - val_categorical_accuracy: 0.8891\n",
      "Epoch 16/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.2250 - categorical_accuracy: 0.9339 - val_loss: 0.3050 - val_categorical_accuracy: 0.8828\n",
      "Epoch 17/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.2080 - categorical_accuracy: 0.9390 - val_loss: 0.3771 - val_categorical_accuracy: 0.8844\n",
      "Epoch 18/100\n",
      "2558/2558 [==============================] - 0s 107us/step - loss: 0.2198 - categorical_accuracy: 0.9371 - val_loss: 0.3288 - val_categorical_accuracy: 0.8906\n",
      "Epoch 19/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.2166 - categorical_accuracy: 0.9347 - val_loss: 0.3273 - val_categorical_accuracy: 0.8891\n",
      "Epoch 20/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.2107 - categorical_accuracy: 0.9371 - val_loss: 0.3457 - val_categorical_accuracy: 0.8719\n",
      "Epoch 21/100\n",
      "2558/2558 [==============================] - 0s 111us/step - loss: 0.2225 - categorical_accuracy: 0.9367 - val_loss: 0.3282 - val_categorical_accuracy: 0.8875\n",
      "Epoch 22/100\n",
      "2558/2558 [==============================] - 0s 155us/step - loss: 0.2130 - categorical_accuracy: 0.9371 - val_loss: 0.3393 - val_categorical_accuracy: 0.8844\n",
      "Epoch 23/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.2246 - categorical_accuracy: 0.9421 - val_loss: 0.3408 - val_categorical_accuracy: 0.8719\n",
      "Epoch 24/100\n",
      "2558/2558 [==============================] - 0s 167us/step - loss: 0.2121 - categorical_accuracy: 0.9347 - val_loss: 0.3315 - val_categorical_accuracy: 0.8953\n",
      "Epoch 25/100\n",
      "2558/2558 [==============================] - 0s 161us/step - loss: 0.2131 - categorical_accuracy: 0.9328 - val_loss: 0.3491 - val_categorical_accuracy: 0.8781\n",
      "Epoch 26/100\n",
      "2558/2558 [==============================] - 0s 149us/step - loss: 0.2042 - categorical_accuracy: 0.9355 - val_loss: 0.3301 - val_categorical_accuracy: 0.8828\n",
      "Epoch 27/100\n",
      "2558/2558 [==============================] - 0s 150us/step - loss: 0.2004 - categorical_accuracy: 0.9398 - val_loss: 0.3372 - val_categorical_accuracy: 0.8813\n",
      "Epoch 28/100\n",
      "2558/2558 [==============================] - 0s 120us/step - loss: 0.2021 - categorical_accuracy: 0.9394 - val_loss: 0.3802 - val_categorical_accuracy: 0.8672\n",
      "Epoch 29/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.2033 - categorical_accuracy: 0.9390 - val_loss: 0.3760 - val_categorical_accuracy: 0.8734\n",
      "Epoch 30/100\n",
      "2558/2558 [==============================] - 0s 140us/step - loss: 0.2051 - categorical_accuracy: 0.9480 - val_loss: 0.3463 - val_categorical_accuracy: 0.8719\n",
      "Epoch 31/100\n",
      "2558/2558 [==============================] - 0s 154us/step - loss: 0.2008 - categorical_accuracy: 0.9461 - val_loss: 0.3748 - val_categorical_accuracy: 0.8766\n",
      "Epoch 32/100\n",
      "2558/2558 [==============================] - 0s 112us/step - loss: 0.2020 - categorical_accuracy: 0.9437 - val_loss: 0.3691 - val_categorical_accuracy: 0.8703\n",
      "Epoch 33/100\n",
      "2558/2558 [==============================] - 0s 163us/step - loss: 0.1874 - categorical_accuracy: 0.9461 - val_loss: 0.3383 - val_categorical_accuracy: 0.8922\n",
      "Epoch 34/100\n",
      "2558/2558 [==============================] - 0s 133us/step - loss: 0.1919 - categorical_accuracy: 0.9476 - val_loss: 0.3621 - val_categorical_accuracy: 0.8828\n",
      "Epoch 35/100\n",
      "2558/2558 [==============================] - 0s 147us/step - loss: 0.1983 - categorical_accuracy: 0.9464 - val_loss: 0.3604 - val_categorical_accuracy: 0.8797\n",
      "Epoch 36/100\n",
      "2558/2558 [==============================] - 0s 147us/step - loss: 0.1965 - categorical_accuracy: 0.9484 - val_loss: 0.3816 - val_categorical_accuracy: 0.8656\n",
      "Epoch 37/100\n",
      "2558/2558 [==============================] - 0s 149us/step - loss: 0.2096 - categorical_accuracy: 0.9406 - val_loss: 0.3613 - val_categorical_accuracy: 0.8844\n",
      "Epoch 38/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.2015 - categorical_accuracy: 0.9386 - val_loss: 0.3666 - val_categorical_accuracy: 0.8875\n",
      "Epoch 39/100\n",
      "2558/2558 [==============================] - 0s 105us/step - loss: 0.1928 - categorical_accuracy: 0.9476 - val_loss: 0.3557 - val_categorical_accuracy: 0.8766\n",
      "Epoch 40/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.1878 - categorical_accuracy: 0.9523 - val_loss: 0.3426 - val_categorical_accuracy: 0.8938\n",
      "Epoch 41/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.1814 - categorical_accuracy: 0.9554 - val_loss: 0.3419 - val_categorical_accuracy: 0.8859\n",
      "Epoch 42/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.1845 - categorical_accuracy: 0.9519 - val_loss: 0.3860 - val_categorical_accuracy: 0.8781\n",
      "Epoch 43/100\n",
      "2558/2558 [==============================] - 0s 126us/step - loss: 0.1824 - categorical_accuracy: 0.9484 - val_loss: 0.3729 - val_categorical_accuracy: 0.8797\n",
      "Epoch 44/100\n",
      "2558/2558 [==============================] - 0s 147us/step - loss: 0.1867 - categorical_accuracy: 0.9468 - val_loss: 0.3590 - val_categorical_accuracy: 0.8781\n",
      "Epoch 45/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.1790 - categorical_accuracy: 0.9488 - val_loss: 0.3588 - val_categorical_accuracy: 0.8828\n",
      "Epoch 46/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.1809 - categorical_accuracy: 0.9550 - val_loss: 0.3861 - val_categorical_accuracy: 0.8766\n",
      "Epoch 47/100\n",
      "2558/2558 [==============================] - 0s 187us/step - loss: 0.1812 - categorical_accuracy: 0.9507 - val_loss: 0.4010 - val_categorical_accuracy: 0.8766\n",
      "Epoch 48/100\n",
      "2558/2558 [==============================] - 0s 192us/step - loss: 0.1856 - categorical_accuracy: 0.9492 - val_loss: 0.3986 - val_categorical_accuracy: 0.8750\n",
      "Epoch 49/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1875 - categorical_accuracy: 0.9523 - val_loss: 0.3979 - val_categorical_accuracy: 0.8781\n",
      "Epoch 50/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1803 - categorical_accuracy: 0.9543 - val_loss: 0.3824 - val_categorical_accuracy: 0.8672\n",
      "Epoch 51/100\n",
      "2558/2558 [==============================] - 0s 176us/step - loss: 0.1934 - categorical_accuracy: 0.9414 - val_loss: 0.3740 - val_categorical_accuracy: 0.8703\n",
      "Epoch 52/100\n",
      "2558/2558 [==============================] - 0s 152us/step - loss: 0.1895 - categorical_accuracy: 0.9468 - val_loss: 0.3970 - val_categorical_accuracy: 0.8625\n",
      "Epoch 53/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.1878 - categorical_accuracy: 0.9480 - val_loss: 0.4076 - val_categorical_accuracy: 0.8687\n",
      "Epoch 54/100\n",
      "2558/2558 [==============================] - 0s 150us/step - loss: 0.1950 - categorical_accuracy: 0.9496 - val_loss: 0.3982 - val_categorical_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "2558/2558 [==============================] - 0s 164us/step - loss: 0.1780 - categorical_accuracy: 0.9519 - val_loss: 0.3886 - val_categorical_accuracy: 0.8844\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2558/2558 [==============================] - 0s 161us/step - loss: 0.1799 - categorical_accuracy: 0.9515 - val_loss: 0.3955 - val_categorical_accuracy: 0.8781\n",
      "Epoch 57/100\n",
      "2558/2558 [==============================] - 0s 121us/step - loss: 0.1812 - categorical_accuracy: 0.9504 - val_loss: 0.3902 - val_categorical_accuracy: 0.8688\n",
      "Epoch 58/100\n",
      "2558/2558 [==============================] - 0s 162us/step - loss: 0.1882 - categorical_accuracy: 0.9449 - val_loss: 0.4224 - val_categorical_accuracy: 0.8750\n",
      "Epoch 59/100\n",
      "2558/2558 [==============================] - 0s 145us/step - loss: 0.1789 - categorical_accuracy: 0.9507 - val_loss: 0.3957 - val_categorical_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.1809 - categorical_accuracy: 0.9519 - val_loss: 0.3928 - val_categorical_accuracy: 0.8688\n",
      "Epoch 61/100\n",
      "2558/2558 [==============================] - 0s 125us/step - loss: 0.1793 - categorical_accuracy: 0.9507 - val_loss: 0.4093 - val_categorical_accuracy: 0.8734\n",
      "Epoch 62/100\n",
      "2558/2558 [==============================] - 0s 173us/step - loss: 0.1736 - categorical_accuracy: 0.9586 - val_loss: 0.3848 - val_categorical_accuracy: 0.8547\n",
      "Epoch 63/100\n",
      "2558/2558 [==============================] - 0s 144us/step - loss: 0.1633 - categorical_accuracy: 0.9601 - val_loss: 0.3682 - val_categorical_accuracy: 0.8687\n",
      "Epoch 64/100\n",
      "2558/2558 [==============================] - 0s 127us/step - loss: 0.1817 - categorical_accuracy: 0.9550 - val_loss: 0.3894 - val_categorical_accuracy: 0.8734\n",
      "Epoch 65/100\n",
      "2558/2558 [==============================] - 0s 117us/step - loss: 0.1693 - categorical_accuracy: 0.9527 - val_loss: 0.4336 - val_categorical_accuracy: 0.8641\n",
      "Epoch 66/100\n",
      "2558/2558 [==============================] - 0s 166us/step - loss: 0.1779 - categorical_accuracy: 0.9527 - val_loss: 0.4006 - val_categorical_accuracy: 0.8781\n",
      "Epoch 67/100\n",
      "2558/2558 [==============================] - 0s 139us/step - loss: 0.1789 - categorical_accuracy: 0.9523 - val_loss: 0.4143 - val_categorical_accuracy: 0.8641\n",
      "Epoch 68/100\n",
      "2558/2558 [==============================] - 0s 141us/step - loss: 0.1693 - categorical_accuracy: 0.9582 - val_loss: 0.4466 - val_categorical_accuracy: 0.8578\n",
      "Epoch 69/100\n",
      "2558/2558 [==============================] - 0s 189us/step - loss: 0.1746 - categorical_accuracy: 0.9539 - val_loss: 0.4371 - val_categorical_accuracy: 0.8625\n",
      "Epoch 70/100\n",
      "2558/2558 [==============================] - 0s 167us/step - loss: 0.1718 - categorical_accuracy: 0.9578 - val_loss: 0.3986 - val_categorical_accuracy: 0.8687\n",
      "Epoch 71/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.1706 - categorical_accuracy: 0.9601 - val_loss: 0.4403 - val_categorical_accuracy: 0.8641\n",
      "Epoch 72/100\n",
      "2558/2558 [==============================] - 0s 120us/step - loss: 0.1836 - categorical_accuracy: 0.9527 - val_loss: 0.4465 - val_categorical_accuracy: 0.8672\n",
      "Epoch 73/100\n",
      "2558/2558 [==============================] - 0s 136us/step - loss: 0.1714 - categorical_accuracy: 0.9547 - val_loss: 0.4023 - val_categorical_accuracy: 0.8656\n",
      "Epoch 74/100\n",
      "2558/2558 [==============================] - 0s 164us/step - loss: 0.1862 - categorical_accuracy: 0.9464 - val_loss: 0.4136 - val_categorical_accuracy: 0.8750\n",
      "Epoch 75/100\n",
      "2558/2558 [==============================] - 0s 161us/step - loss: 0.1739 - categorical_accuracy: 0.9558 - val_loss: 0.4407 - val_categorical_accuracy: 0.8641\n",
      "Epoch 76/100\n",
      "2558/2558 [==============================] - 0s 106us/step - loss: 0.1809 - categorical_accuracy: 0.9523 - val_loss: 0.3898 - val_categorical_accuracy: 0.8797\n",
      "Epoch 77/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.1870 - categorical_accuracy: 0.9507 - val_loss: 0.4109 - val_categorical_accuracy: 0.8703\n",
      "Epoch 78/100\n",
      "2558/2558 [==============================] - 0s 128us/step - loss: 0.1647 - categorical_accuracy: 0.9578 - val_loss: 0.4171 - val_categorical_accuracy: 0.8656\n",
      "Epoch 79/100\n",
      "2558/2558 [==============================] - 0s 118us/step - loss: 0.1742 - categorical_accuracy: 0.9539 - val_loss: 0.4054 - val_categorical_accuracy: 0.8781\n",
      "Epoch 80/100\n",
      "2558/2558 [==============================] - 0s 111us/step - loss: 0.1604 - categorical_accuracy: 0.9605 - val_loss: 0.4471 - val_categorical_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.1681 - categorical_accuracy: 0.9574 - val_loss: 0.4219 - val_categorical_accuracy: 0.8578\n",
      "Epoch 82/100\n",
      "2558/2558 [==============================] - 0s 170us/step - loss: 0.1610 - categorical_accuracy: 0.9629 - val_loss: 0.4390 - val_categorical_accuracy: 0.8766\n",
      "Epoch 83/100\n",
      "2558/2558 [==============================] - 0s 148us/step - loss: 0.1693 - categorical_accuracy: 0.9550 - val_loss: 0.4627 - val_categorical_accuracy: 0.8516\n",
      "Epoch 84/100\n",
      "2558/2558 [==============================] - 0s 146us/step - loss: 0.1766 - categorical_accuracy: 0.9547 - val_loss: 0.4329 - val_categorical_accuracy: 0.8562\n",
      "Epoch 85/100\n",
      "2558/2558 [==============================] - 0s 121us/step - loss: 0.1784 - categorical_accuracy: 0.9543 - val_loss: 0.4131 - val_categorical_accuracy: 0.8766\n",
      "Epoch 86/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1709 - categorical_accuracy: 0.9570 - val_loss: 0.3770 - val_categorical_accuracy: 0.8703\n",
      "Epoch 87/100\n",
      "2558/2558 [==============================] - 0s 153us/step - loss: 0.1707 - categorical_accuracy: 0.9558 - val_loss: 0.4041 - val_categorical_accuracy: 0.8672\n",
      "Epoch 88/100\n",
      "2558/2558 [==============================] - 0s 143us/step - loss: 0.1813 - categorical_accuracy: 0.9504 - val_loss: 0.4258 - val_categorical_accuracy: 0.8562\n",
      "Epoch 89/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1743 - categorical_accuracy: 0.9515 - val_loss: 0.4395 - val_categorical_accuracy: 0.8766\n",
      "Epoch 90/100\n",
      "2558/2558 [==============================] - 0s 153us/step - loss: 0.1795 - categorical_accuracy: 0.9543 - val_loss: 0.3972 - val_categorical_accuracy: 0.8719\n",
      "Epoch 91/100\n",
      "2558/2558 [==============================] - 0s 140us/step - loss: 0.1808 - categorical_accuracy: 0.9531 - val_loss: 0.4731 - val_categorical_accuracy: 0.8500\n",
      "Epoch 92/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.1696 - categorical_accuracy: 0.9590 - val_loss: 0.3813 - val_categorical_accuracy: 0.8922\n",
      "Epoch 93/100\n",
      "2558/2558 [==============================] - 0s 124us/step - loss: 0.1729 - categorical_accuracy: 0.9543 - val_loss: 0.4329 - val_categorical_accuracy: 0.8609\n",
      "Epoch 94/100\n",
      "2558/2558 [==============================] - 0s 137us/step - loss: 0.1768 - categorical_accuracy: 0.9539 - val_loss: 0.3862 - val_categorical_accuracy: 0.8813\n",
      "Epoch 95/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1701 - categorical_accuracy: 0.9570 - val_loss: 0.4354 - val_categorical_accuracy: 0.8656\n",
      "Epoch 96/100\n",
      "2558/2558 [==============================] - 0s 131us/step - loss: 0.1697 - categorical_accuracy: 0.9617 - val_loss: 0.4370 - val_categorical_accuracy: 0.8703\n",
      "Epoch 97/100\n",
      "2558/2558 [==============================] - 0s 138us/step - loss: 0.1647 - categorical_accuracy: 0.9582 - val_loss: 0.4401 - val_categorical_accuracy: 0.8703\n",
      "Epoch 98/100\n",
      "2558/2558 [==============================] - 0s 159us/step - loss: 0.1628 - categorical_accuracy: 0.9578 - val_loss: 0.4324 - val_categorical_accuracy: 0.8750\n",
      "Epoch 99/100\n",
      "2558/2558 [==============================] - 0s 129us/step - loss: 0.1644 - categorical_accuracy: 0.9609 - val_loss: 0.4017 - val_categorical_accuracy: 0.8750\n",
      "Epoch 100/100\n",
      "2558/2558 [==============================] - 0s 151us/step - loss: 0.1673 - categorical_accuracy: 0.9566 - val_loss: 0.4143 - val_categorical_accuracy: 0.8672\n",
      "2022-11-09 02:55:19,141: INFO): Train Y: [1280. 1280.]\n",
      "2022-11-09 02:55:19,871: INFO): Model build\n",
      "Train on 2560 samples, validate on 638 samples\n",
      "Epoch 1/100\n",
      "2560/2560 [==============================] - 1s 558us/step - loss: 0.6833 - categorical_accuracy: 0.7047 - val_loss: 0.4711 - val_categorical_accuracy: 0.8009\n",
      "Epoch 2/100\n",
      "2560/2560 [==============================] - 0s 120us/step - loss: 0.4120 - categorical_accuracy: 0.8520 - val_loss: 0.4170 - val_categorical_accuracy: 0.8292\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 0s 135us/step - loss: 0.3530 - categorical_accuracy: 0.8770 - val_loss: 0.3687 - val_categorical_accuracy: 0.8683\n",
      "Epoch 4/100\n",
      "2560/2560 [==============================] - 0s 120us/step - loss: 0.3225 - categorical_accuracy: 0.8871 - val_loss: 0.3669 - val_categorical_accuracy: 0.8480\n",
      "Epoch 5/100\n",
      "2560/2560 [==============================] - 0s 148us/step - loss: 0.3113 - categorical_accuracy: 0.8914 - val_loss: 0.3647 - val_categorical_accuracy: 0.8652\n",
      "Epoch 6/100\n",
      "2560/2560 [==============================] - 0s 147us/step - loss: 0.3054 - categorical_accuracy: 0.8980 - val_loss: 0.3532 - val_categorical_accuracy: 0.8856\n",
      "Epoch 7/100\n",
      "2560/2560 [==============================] - 0s 145us/step - loss: 0.2928 - categorical_accuracy: 0.9023 - val_loss: 0.3514 - val_categorical_accuracy: 0.8762\n",
      "Epoch 8/100\n",
      "2560/2560 [==============================] - 0s 159us/step - loss: 0.2775 - categorical_accuracy: 0.9082 - val_loss: 0.3456 - val_categorical_accuracy: 0.8777\n",
      "Epoch 9/100\n",
      "2560/2560 [==============================] - 0s 156us/step - loss: 0.2739 - categorical_accuracy: 0.9117 - val_loss: 0.3706 - val_categorical_accuracy: 0.8683\n",
      "Epoch 10/100\n",
      "2560/2560 [==============================] - 0s 154us/step - loss: 0.2792 - categorical_accuracy: 0.9027 - val_loss: 0.3394 - val_categorical_accuracy: 0.8809\n",
      "Epoch 11/100\n",
      "2560/2560 [==============================] - 0s 138us/step - loss: 0.2632 - categorical_accuracy: 0.9172 - val_loss: 0.3389 - val_categorical_accuracy: 0.8762\n",
      "Epoch 12/100\n",
      "2560/2560 [==============================] - 0s 170us/step - loss: 0.2608 - categorical_accuracy: 0.9172 - val_loss: 0.3364 - val_categorical_accuracy: 0.8887\n",
      "Epoch 13/100\n",
      "2560/2560 [==============================] - 0s 126us/step - loss: 0.2591 - categorical_accuracy: 0.9160 - val_loss: 0.3514 - val_categorical_accuracy: 0.8746\n",
      "Epoch 14/100\n",
      "2560/2560 [==============================] - 0s 153us/step - loss: 0.2569 - categorical_accuracy: 0.9168 - val_loss: 0.3494 - val_categorical_accuracy: 0.8699\n",
      "Epoch 15/100\n",
      "2560/2560 [==============================] - 0s 133us/step - loss: 0.2397 - categorical_accuracy: 0.9266 - val_loss: 0.3313 - val_categorical_accuracy: 0.8887\n",
      "Epoch 16/100\n",
      "2560/2560 [==============================] - 0s 147us/step - loss: 0.2485 - categorical_accuracy: 0.9223 - val_loss: 0.3252 - val_categorical_accuracy: 0.8762\n",
      "Epoch 17/100\n",
      "2560/2560 [==============================] - 0s 135us/step - loss: 0.2435 - categorical_accuracy: 0.9238 - val_loss: 0.3388 - val_categorical_accuracy: 0.8699\n",
      "Epoch 18/100\n",
      "2560/2560 [==============================] - 0s 116us/step - loss: 0.2456 - categorical_accuracy: 0.9230 - val_loss: 0.3372 - val_categorical_accuracy: 0.8856\n",
      "Epoch 19/100\n",
      "2560/2560 [==============================] - 0s 122us/step - loss: 0.2437 - categorical_accuracy: 0.9207 - val_loss: 0.3442 - val_categorical_accuracy: 0.8636\n",
      "Epoch 20/100\n",
      "2560/2560 [==============================] - 0s 135us/step - loss: 0.2398 - categorical_accuracy: 0.9227 - val_loss: 0.3395 - val_categorical_accuracy: 0.8824\n",
      "Epoch 21/100\n",
      "2560/2560 [==============================] - 0s 133us/step - loss: 0.2425 - categorical_accuracy: 0.9227 - val_loss: 0.3561 - val_categorical_accuracy: 0.8762\n",
      "Epoch 22/100\n",
      "2560/2560 [==============================] - 0s 148us/step - loss: 0.2348 - categorical_accuracy: 0.9246 - val_loss: 0.3561 - val_categorical_accuracy: 0.8668\n",
      "Epoch 23/100\n",
      "2560/2560 [==============================] - 0s 108us/step - loss: 0.2293 - categorical_accuracy: 0.9332 - val_loss: 0.3336 - val_categorical_accuracy: 0.8793\n",
      "Epoch 24/100\n",
      "2560/2560 [==============================] - 0s 123us/step - loss: 0.2249 - categorical_accuracy: 0.9328 - val_loss: 0.3452 - val_categorical_accuracy: 0.8840\n",
      "Epoch 25/100\n",
      "2560/2560 [==============================] - 0s 114us/step - loss: 0.2328 - categorical_accuracy: 0.9277 - val_loss: 0.3651 - val_categorical_accuracy: 0.8730\n",
      "Epoch 26/100\n",
      "2560/2560 [==============================] - 0s 117us/step - loss: 0.2283 - categorical_accuracy: 0.9273 - val_loss: 0.3195 - val_categorical_accuracy: 0.8793\n",
      "Epoch 27/100\n",
      "2560/2560 [==============================] - 0s 121us/step - loss: 0.2246 - categorical_accuracy: 0.9320 - val_loss: 0.3646 - val_categorical_accuracy: 0.8762\n",
      "Epoch 28/100\n",
      "2560/2560 [==============================] - 0s 135us/step - loss: 0.2280 - categorical_accuracy: 0.9293 - val_loss: 0.3599 - val_categorical_accuracy: 0.8746\n",
      "Epoch 29/100\n",
      "2560/2560 [==============================] - 0s 146us/step - loss: 0.2267 - categorical_accuracy: 0.9348 - val_loss: 0.3476 - val_categorical_accuracy: 0.8777\n",
      "Epoch 30/100\n",
      "2560/2560 [==============================] - 0s 110us/step - loss: 0.2207 - categorical_accuracy: 0.9328 - val_loss: 0.3540 - val_categorical_accuracy: 0.8777\n",
      "Epoch 31/100\n",
      "2560/2560 [==============================] - 0s 180us/step - loss: 0.2198 - categorical_accuracy: 0.9328 - val_loss: 0.3510 - val_categorical_accuracy: 0.8652\n",
      "Epoch 32/100\n",
      "2560/2560 [==============================] - 0s 166us/step - loss: 0.2173 - categorical_accuracy: 0.9344 - val_loss: 0.3645 - val_categorical_accuracy: 0.8730\n",
      "Epoch 33/100\n",
      "2560/2560 [==============================] - 0s 153us/step - loss: 0.2128 - categorical_accuracy: 0.9402 - val_loss: 0.3469 - val_categorical_accuracy: 0.8856\n",
      "Epoch 34/100\n",
      "2560/2560 [==============================] - 0s 142us/step - loss: 0.2117 - categorical_accuracy: 0.9336 - val_loss: 0.3797 - val_categorical_accuracy: 0.8762\n",
      "Epoch 35/100\n",
      "2560/2560 [==============================] - 0s 131us/step - loss: 0.2150 - categorical_accuracy: 0.9371 - val_loss: 0.3690 - val_categorical_accuracy: 0.8777\n",
      "Epoch 36/100\n",
      "2560/2560 [==============================] - 0s 127us/step - loss: 0.2127 - categorical_accuracy: 0.9402 - val_loss: 0.3617 - val_categorical_accuracy: 0.8730\n",
      "Epoch 37/100\n",
      "2560/2560 [==============================] - 0s 147us/step - loss: 0.2127 - categorical_accuracy: 0.9363 - val_loss: 0.4023 - val_categorical_accuracy: 0.8636\n",
      "Epoch 38/100\n",
      "2560/2560 [==============================] - 0s 124us/step - loss: 0.2131 - categorical_accuracy: 0.9336 - val_loss: 0.3356 - val_categorical_accuracy: 0.8809\n",
      "Epoch 39/100\n",
      "2560/2560 [==============================] - 0s 123us/step - loss: 0.2055 - categorical_accuracy: 0.9375 - val_loss: 0.3830 - val_categorical_accuracy: 0.8856\n",
      "Epoch 40/100\n",
      "2560/2560 [==============================] - 0s 132us/step - loss: 0.2061 - categorical_accuracy: 0.9363 - val_loss: 0.3708 - val_categorical_accuracy: 0.8730\n",
      "Epoch 41/100\n",
      "2560/2560 [==============================] - 0s 128us/step - loss: 0.2128 - categorical_accuracy: 0.9336 - val_loss: 0.3827 - val_categorical_accuracy: 0.8730\n",
      "Epoch 42/100\n",
      "2560/2560 [==============================] - 0s 153us/step - loss: 0.2063 - categorical_accuracy: 0.9430 - val_loss: 0.3708 - val_categorical_accuracy: 0.8730\n",
      "Epoch 43/100\n",
      "2560/2560 [==============================] - 0s 126us/step - loss: 0.2107 - categorical_accuracy: 0.9387 - val_loss: 0.3385 - val_categorical_accuracy: 0.8887\n",
      "Epoch 44/100\n",
      "2560/2560 [==============================] - 0s 146us/step - loss: 0.2158 - categorical_accuracy: 0.9398 - val_loss: 0.3622 - val_categorical_accuracy: 0.8746\n",
      "Epoch 45/100\n",
      "2560/2560 [==============================] - 0s 156us/step - loss: 0.2027 - categorical_accuracy: 0.9398 - val_loss: 0.3671 - val_categorical_accuracy: 0.8589\n",
      "Epoch 46/100\n",
      "2560/2560 [==============================] - 0s 135us/step - loss: 0.1997 - categorical_accuracy: 0.9430 - val_loss: 0.3783 - val_categorical_accuracy: 0.8621\n",
      "Epoch 47/100\n",
      "2560/2560 [==============================] - 0s 136us/step - loss: 0.1983 - categorical_accuracy: 0.9398 - val_loss: 0.3853 - val_categorical_accuracy: 0.8730\n",
      "Epoch 48/100\n",
      "2560/2560 [==============================] - 0s 148us/step - loss: 0.2059 - categorical_accuracy: 0.9426 - val_loss: 0.3623 - val_categorical_accuracy: 0.8809\n",
      "Epoch 49/100\n",
      "2560/2560 [==============================] - 0s 146us/step - loss: 0.2033 - categorical_accuracy: 0.9430 - val_loss: 0.3858 - val_categorical_accuracy: 0.8793\n",
      "Epoch 50/100\n",
      "2560/2560 [==============================] - 0s 116us/step - loss: 0.2019 - categorical_accuracy: 0.9379 - val_loss: 0.3565 - val_categorical_accuracy: 0.8793\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 0s 130us/step - loss: 0.2103 - categorical_accuracy: 0.9352 - val_loss: 0.3786 - val_categorical_accuracy: 0.8746\n",
      "Epoch 52/100\n",
      "2560/2560 [==============================] - 0s 102us/step - loss: 0.1962 - categorical_accuracy: 0.9441 - val_loss: 0.3598 - val_categorical_accuracy: 0.8793\n",
      "Epoch 53/100\n",
      "2560/2560 [==============================] - 0s 170us/step - loss: 0.2013 - categorical_accuracy: 0.9418 - val_loss: 0.4034 - val_categorical_accuracy: 0.8699\n",
      "Epoch 54/100\n",
      "2560/2560 [==============================] - 0s 112us/step - loss: 0.1966 - categorical_accuracy: 0.9410 - val_loss: 0.3807 - val_categorical_accuracy: 0.8746\n",
      "Epoch 55/100\n",
      "2560/2560 [==============================] - 0s 116us/step - loss: 0.2017 - categorical_accuracy: 0.9418 - val_loss: 0.3833 - val_categorical_accuracy: 0.8793\n",
      "Epoch 56/100\n",
      "2560/2560 [==============================] - 0s 146us/step - loss: 0.1899 - categorical_accuracy: 0.9477 - val_loss: 0.3902 - val_categorical_accuracy: 0.8730\n",
      "Epoch 57/100\n",
      "2560/2560 [==============================] - 0s 107us/step - loss: 0.2016 - categorical_accuracy: 0.9367 - val_loss: 0.3951 - val_categorical_accuracy: 0.8793\n",
      "Epoch 58/100\n",
      "2560/2560 [==============================] - 0s 111us/step - loss: 0.1993 - categorical_accuracy: 0.9410 - val_loss: 0.3733 - val_categorical_accuracy: 0.8824\n",
      "Epoch 59/100\n",
      "2560/2560 [==============================] - 0s 164us/step - loss: 0.1930 - categorical_accuracy: 0.9477 - val_loss: 0.3648 - val_categorical_accuracy: 0.8824\n",
      "Epoch 60/100\n",
      "2560/2560 [==============================] - 0s 160us/step - loss: 0.1913 - categorical_accuracy: 0.9496 - val_loss: 0.3940 - val_categorical_accuracy: 0.8809\n",
      "Epoch 61/100\n",
      "2560/2560 [==============================] - 0s 138us/step - loss: 0.1960 - categorical_accuracy: 0.9449 - val_loss: 0.3937 - val_categorical_accuracy: 0.8699\n",
      "Epoch 62/100\n",
      "2560/2560 [==============================] - 0s 122us/step - loss: 0.1884 - categorical_accuracy: 0.9504 - val_loss: 0.3828 - val_categorical_accuracy: 0.8762\n",
      "Epoch 63/100\n",
      "2560/2560 [==============================] - 0s 129us/step - loss: 0.1961 - categorical_accuracy: 0.9492 - val_loss: 0.3727 - val_categorical_accuracy: 0.8793\n",
      "Epoch 64/100\n",
      "2560/2560 [==============================] - 0s 135us/step - loss: 0.1962 - categorical_accuracy: 0.9418 - val_loss: 0.3344 - val_categorical_accuracy: 0.8793\n",
      "Epoch 65/100\n",
      "2560/2560 [==============================] - 0s 133us/step - loss: 0.2013 - categorical_accuracy: 0.9340 - val_loss: 0.3990 - val_categorical_accuracy: 0.8605\n",
      "Epoch 66/100\n",
      "2560/2560 [==============================] - 0s 130us/step - loss: 0.1944 - categorical_accuracy: 0.9449 - val_loss: 0.3767 - val_categorical_accuracy: 0.8824\n",
      "Epoch 67/100\n",
      "2560/2560 [==============================] - 0s 162us/step - loss: 0.1953 - categorical_accuracy: 0.9461 - val_loss: 0.3616 - val_categorical_accuracy: 0.8793\n",
      "Epoch 68/100\n",
      "2560/2560 [==============================] - 0s 126us/step - loss: 0.1857 - categorical_accuracy: 0.9500 - val_loss: 0.3799 - val_categorical_accuracy: 0.8809\n",
      "Epoch 69/100\n",
      "2560/2560 [==============================] - 0s 154us/step - loss: 0.1857 - categorical_accuracy: 0.9512 - val_loss: 0.4036 - val_categorical_accuracy: 0.8777\n",
      "Epoch 70/100\n",
      "2560/2560 [==============================] - 0s 156us/step - loss: 0.1940 - categorical_accuracy: 0.9453 - val_loss: 0.3905 - val_categorical_accuracy: 0.8871\n",
      "Epoch 71/100\n",
      "2560/2560 [==============================] - 0s 150us/step - loss: 0.1928 - categorical_accuracy: 0.9449 - val_loss: 0.3789 - val_categorical_accuracy: 0.8715\n",
      "Epoch 72/100\n",
      "2560/2560 [==============================] - 0s 128us/step - loss: 0.1872 - categorical_accuracy: 0.9523 - val_loss: 0.3945 - val_categorical_accuracy: 0.8840\n",
      "Epoch 73/100\n",
      "2560/2560 [==============================] - 0s 124us/step - loss: 0.1882 - categorical_accuracy: 0.9512 - val_loss: 0.4141 - val_categorical_accuracy: 0.8793\n",
      "Epoch 74/100\n",
      "2560/2560 [==============================] - 0s 151us/step - loss: 0.1755 - categorical_accuracy: 0.9602 - val_loss: 0.4027 - val_categorical_accuracy: 0.8793\n",
      "Epoch 75/100\n",
      "2560/2560 [==============================] - 0s 132us/step - loss: 0.1865 - categorical_accuracy: 0.9488 - val_loss: 0.4051 - val_categorical_accuracy: 0.8793\n",
      "Epoch 76/100\n",
      "2560/2560 [==============================] - 0s 187us/step - loss: 0.1879 - categorical_accuracy: 0.9484 - val_loss: 0.3650 - val_categorical_accuracy: 0.8840\n",
      "Epoch 77/100\n",
      "2560/2560 [==============================] - 0s 155us/step - loss: 0.1770 - categorical_accuracy: 0.9547 - val_loss: 0.3934 - val_categorical_accuracy: 0.8746\n",
      "Epoch 78/100\n",
      "2560/2560 [==============================] - 0s 127us/step - loss: 0.1863 - categorical_accuracy: 0.9492 - val_loss: 0.4131 - val_categorical_accuracy: 0.8668\n",
      "Epoch 79/100\n",
      "2560/2560 [==============================] - 0s 114us/step - loss: 0.1786 - categorical_accuracy: 0.9578 - val_loss: 0.4036 - val_categorical_accuracy: 0.8746\n",
      "Epoch 80/100\n",
      "2560/2560 [==============================] - 0s 114us/step - loss: 0.1825 - categorical_accuracy: 0.9555 - val_loss: 0.4053 - val_categorical_accuracy: 0.8824\n",
      "Epoch 81/100\n",
      "2560/2560 [==============================] - 0s 176us/step - loss: 0.1825 - categorical_accuracy: 0.9496 - val_loss: 0.3993 - val_categorical_accuracy: 0.8840\n",
      "Epoch 82/100\n",
      "2560/2560 [==============================] - 0s 139us/step - loss: 0.1831 - categorical_accuracy: 0.9469 - val_loss: 0.4115 - val_categorical_accuracy: 0.8903\n",
      "Epoch 83/100\n",
      "2560/2560 [==============================] - 0s 138us/step - loss: 0.1819 - categorical_accuracy: 0.9512 - val_loss: 0.4341 - val_categorical_accuracy: 0.8605\n",
      "Epoch 84/100\n",
      "2560/2560 [==============================] - 0s 178us/step - loss: 0.1780 - categorical_accuracy: 0.9547 - val_loss: 0.3867 - val_categorical_accuracy: 0.8824\n",
      "Epoch 85/100\n",
      "2560/2560 [==============================] - 0s 165us/step - loss: 0.1913 - categorical_accuracy: 0.9434 - val_loss: 0.4301 - val_categorical_accuracy: 0.8715\n",
      "Epoch 86/100\n",
      "2560/2560 [==============================] - 0s 156us/step - loss: 0.1813 - categorical_accuracy: 0.9512 - val_loss: 0.4259 - val_categorical_accuracy: 0.8636\n",
      "Epoch 87/100\n",
      "2560/2560 [==============================] - 0s 134us/step - loss: 0.1878 - categorical_accuracy: 0.9457 - val_loss: 0.4086 - val_categorical_accuracy: 0.8840\n",
      "Epoch 88/100\n",
      "2560/2560 [==============================] - 0s 180us/step - loss: 0.1847 - categorical_accuracy: 0.9543 - val_loss: 0.4265 - val_categorical_accuracy: 0.8715\n",
      "Epoch 89/100\n",
      "2560/2560 [==============================] - 0s 138us/step - loss: 0.1834 - categorical_accuracy: 0.9508 - val_loss: 0.4572 - val_categorical_accuracy: 0.8621\n",
      "Epoch 90/100\n",
      "2560/2560 [==============================] - 0s 115us/step - loss: 0.1833 - categorical_accuracy: 0.9488 - val_loss: 0.4044 - val_categorical_accuracy: 0.8683\n",
      "Epoch 91/100\n",
      "2560/2560 [==============================] - 0s 142us/step - loss: 0.1763 - categorical_accuracy: 0.9520 - val_loss: 0.4385 - val_categorical_accuracy: 0.8871\n",
      "Epoch 92/100\n",
      "2560/2560 [==============================] - 0s 123us/step - loss: 0.1754 - categorical_accuracy: 0.9512 - val_loss: 0.4357 - val_categorical_accuracy: 0.8730\n",
      "Epoch 93/100\n",
      "2560/2560 [==============================] - 0s 142us/step - loss: 0.1687 - categorical_accuracy: 0.9535 - val_loss: 0.4369 - val_categorical_accuracy: 0.8730\n",
      "Epoch 94/100\n",
      "2560/2560 [==============================] - 0s 124us/step - loss: 0.1746 - categorical_accuracy: 0.9555 - val_loss: 0.4044 - val_categorical_accuracy: 0.8683\n",
      "Epoch 95/100\n",
      "2560/2560 [==============================] - 0s 111us/step - loss: 0.1804 - categorical_accuracy: 0.9496 - val_loss: 0.4198 - val_categorical_accuracy: 0.8699\n",
      "Epoch 96/100\n",
      "2560/2560 [==============================] - 0s 143us/step - loss: 0.1737 - categorical_accuracy: 0.9574 - val_loss: 0.4330 - val_categorical_accuracy: 0.8730\n",
      "Epoch 97/100\n",
      "2560/2560 [==============================] - 0s 163us/step - loss: 0.1737 - categorical_accuracy: 0.9531 - val_loss: 0.4817 - val_categorical_accuracy: 0.8605\n",
      "Epoch 98/100\n",
      "2560/2560 [==============================] - 0s 176us/step - loss: 0.1682 - categorical_accuracy: 0.9574 - val_loss: 0.4365 - val_categorical_accuracy: 0.8621\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2560/2560 [==============================] - 0s 173us/step - loss: 0.1734 - categorical_accuracy: 0.9559 - val_loss: 0.4343 - val_categorical_accuracy: 0.8589\n",
      "Epoch 100/100\n",
      "2560/2560 [==============================] - 0s 156us/step - loss: 0.1781 - categorical_accuracy: 0.9508 - val_loss: 0.4350 - val_categorical_accuracy: 0.8683\n",
      "2022-11-09 02:55:57,595: INFO): Val loss: 11-0.334420\n",
      "2022-11-09 02:55:57,595: INFO): Testing\n",
      "no external\n",
      "2022-11-09 02:55:58,455: INFO): Model build\n",
      "Train on 3198 samples, validate on 356 samples\n",
      "Epoch 1/100\n",
      "3198/3198 [==============================] - 2s 500us/step - loss: 0.4993 - categorical_accuracy: 0.7864 - val_loss: 0.4554 - val_categorical_accuracy: 0.8034\n",
      "Epoch 2/100\n",
      "3198/3198 [==============================] - 0s 125us/step - loss: 0.3410 - categorical_accuracy: 0.8812 - val_loss: 0.3966 - val_categorical_accuracy: 0.8258\n",
      "Epoch 3/100\n",
      "3198/3198 [==============================] - 1s 160us/step - loss: 0.3010 - categorical_accuracy: 0.9031 - val_loss: 0.4012 - val_categorical_accuracy: 0.8287\n",
      "Epoch 4/100\n",
      "3198/3198 [==============================] - 0s 141us/step - loss: 0.2854 - categorical_accuracy: 0.9046 - val_loss: 0.4091 - val_categorical_accuracy: 0.8315\n",
      "Epoch 5/100\n",
      "3198/3198 [==============================] - 0s 133us/step - loss: 0.2825 - categorical_accuracy: 0.9159 - val_loss: 0.4623 - val_categorical_accuracy: 0.8315\n",
      "Epoch 6/100\n",
      "3198/3198 [==============================] - 0s 105us/step - loss: 0.2671 - categorical_accuracy: 0.9149 - val_loss: 0.4548 - val_categorical_accuracy: 0.8343\n",
      "Epoch 7/100\n",
      "3198/3198 [==============================] - 0s 156us/step - loss: 0.2560 - categorical_accuracy: 0.9162 - val_loss: 0.4385 - val_categorical_accuracy: 0.8202\n",
      "Epoch 8/100\n",
      "3198/3198 [==============================] - 0s 148us/step - loss: 0.2589 - categorical_accuracy: 0.9221 - val_loss: 0.4480 - val_categorical_accuracy: 0.8539\n",
      "Epoch 9/100\n",
      "3198/3198 [==============================] - 0s 149us/step - loss: 0.2520 - categorical_accuracy: 0.9128 - val_loss: 0.4213 - val_categorical_accuracy: 0.8399\n",
      "Epoch 10/100\n",
      "3198/3198 [==============================] - 1s 157us/step - loss: 0.2445 - categorical_accuracy: 0.9199 - val_loss: 0.4382 - val_categorical_accuracy: 0.8287\n",
      "Epoch 11/100\n",
      "3198/3198 [==============================] - 0s 125us/step - loss: 0.2490 - categorical_accuracy: 0.9215 - val_loss: 0.4365 - val_categorical_accuracy: 0.8315\n",
      "Epoch 12/100\n",
      "3198/3198 [==============================] - 0s 118us/step - loss: 0.2467 - categorical_accuracy: 0.9203 - val_loss: 0.4382 - val_categorical_accuracy: 0.8399\n",
      "Epoch 13/100\n",
      "3198/3198 [==============================] - 0s 108us/step - loss: 0.2427 - categorical_accuracy: 0.9212 - val_loss: 0.4083 - val_categorical_accuracy: 0.8596\n",
      "Epoch 14/100\n",
      "3198/3198 [==============================] - 0s 144us/step - loss: 0.2270 - categorical_accuracy: 0.9325 - val_loss: 0.4310 - val_categorical_accuracy: 0.8287\n",
      "Epoch 15/100\n",
      "3198/3198 [==============================] - 0s 147us/step - loss: 0.2222 - categorical_accuracy: 0.9325 - val_loss: 0.4645 - val_categorical_accuracy: 0.8230\n",
      "Epoch 16/100\n",
      "3198/3198 [==============================] - 0s 143us/step - loss: 0.2261 - categorical_accuracy: 0.9325 - val_loss: 0.4419 - val_categorical_accuracy: 0.8399\n",
      "Epoch 17/100\n",
      "3198/3198 [==============================] - 0s 120us/step - loss: 0.2196 - categorical_accuracy: 0.9287 - val_loss: 0.4019 - val_categorical_accuracy: 0.8511\n",
      "Epoch 18/100\n",
      "3198/3198 [==============================] - 1s 158us/step - loss: 0.2270 - categorical_accuracy: 0.9281 - val_loss: 0.4328 - val_categorical_accuracy: 0.8343\n",
      "Epoch 19/100\n",
      "3198/3198 [==============================] - 1s 164us/step - loss: 0.2223 - categorical_accuracy: 0.9309 - val_loss: 0.4351 - val_categorical_accuracy: 0.8287\n",
      "Epoch 20/100\n",
      "3198/3198 [==============================] - 0s 139us/step - loss: 0.2279 - categorical_accuracy: 0.9309 - val_loss: 0.4359 - val_categorical_accuracy: 0.8287\n",
      "Epoch 21/100\n",
      "3198/3198 [==============================] - 0s 124us/step - loss: 0.2279 - categorical_accuracy: 0.9318 - val_loss: 0.3932 - val_categorical_accuracy: 0.8343\n",
      "Epoch 22/100\n",
      "3198/3198 [==============================] - 0s 129us/step - loss: 0.2254 - categorical_accuracy: 0.9256 - val_loss: 0.4154 - val_categorical_accuracy: 0.8624\n",
      "Epoch 23/100\n",
      "3198/3198 [==============================] - 1s 188us/step - loss: 0.2181 - categorical_accuracy: 0.9359 - val_loss: 0.4182 - val_categorical_accuracy: 0.8511\n",
      "Epoch 24/100\n",
      "3198/3198 [==============================] - 0s 132us/step - loss: 0.2188 - categorical_accuracy: 0.9325 - val_loss: 0.4450 - val_categorical_accuracy: 0.8230\n",
      "Epoch 25/100\n",
      "3198/3198 [==============================] - 0s 133us/step - loss: 0.2217 - categorical_accuracy: 0.9303 - val_loss: 0.4168 - val_categorical_accuracy: 0.8483\n",
      "Epoch 26/100\n",
      "3198/3198 [==============================] - 0s 148us/step - loss: 0.2131 - categorical_accuracy: 0.9375 - val_loss: 0.4219 - val_categorical_accuracy: 0.8455\n",
      "Epoch 27/100\n",
      "3198/3198 [==============================] - 1s 191us/step - loss: 0.2259 - categorical_accuracy: 0.9309 - val_loss: 0.4474 - val_categorical_accuracy: 0.8343\n",
      "Epoch 28/100\n",
      "3198/3198 [==============================] - 1s 163us/step - loss: 0.2201 - categorical_accuracy: 0.9312 - val_loss: 0.4385 - val_categorical_accuracy: 0.8315\n",
      "Epoch 29/100\n",
      "3198/3198 [==============================] - 0s 139us/step - loss: 0.2116 - categorical_accuracy: 0.9378 - val_loss: 0.4662 - val_categorical_accuracy: 0.8258\n",
      "Epoch 30/100\n",
      "3198/3198 [==============================] - 0s 149us/step - loss: 0.2087 - categorical_accuracy: 0.9387 - val_loss: 0.4507 - val_categorical_accuracy: 0.8371\n",
      "Epoch 31/100\n",
      "3198/3198 [==============================] - 0s 123us/step - loss: 0.2094 - categorical_accuracy: 0.9393 - val_loss: 0.4729 - val_categorical_accuracy: 0.8567\n",
      "Epoch 32/100\n",
      "3198/3198 [==============================] - 0s 133us/step - loss: 0.2109 - categorical_accuracy: 0.9384 - val_loss: 0.4802 - val_categorical_accuracy: 0.8146\n",
      "Epoch 33/100\n",
      "3198/3198 [==============================] - 0s 136us/step - loss: 0.2116 - categorical_accuracy: 0.9346 - val_loss: 0.4539 - val_categorical_accuracy: 0.8399\n",
      "Epoch 34/100\n",
      "3198/3198 [==============================] - 0s 122us/step - loss: 0.2011 - categorical_accuracy: 0.9378 - val_loss: 0.4655 - val_categorical_accuracy: 0.8567\n",
      "Epoch 35/100\n",
      "3198/3198 [==============================] - 0s 123us/step - loss: 0.2124 - categorical_accuracy: 0.9393 - val_loss: 0.4152 - val_categorical_accuracy: 0.8708\n",
      "Epoch 36/100\n",
      "3198/3198 [==============================] - 0s 127us/step - loss: 0.2075 - categorical_accuracy: 0.9371 - val_loss: 0.4767 - val_categorical_accuracy: 0.8230\n",
      "Epoch 37/100\n",
      "3198/3198 [==============================] - 0s 105us/step - loss: 0.2084 - categorical_accuracy: 0.9387 - val_loss: 0.5059 - val_categorical_accuracy: 0.8230\n",
      "Epoch 38/100\n",
      "3198/3198 [==============================] - 0s 136us/step - loss: 0.2036 - categorical_accuracy: 0.9431 - val_loss: 0.4155 - val_categorical_accuracy: 0.8343\n",
      "Epoch 39/100\n",
      "3198/3198 [==============================] - 0s 117us/step - loss: 0.2121 - categorical_accuracy: 0.9331 - val_loss: 0.4078 - val_categorical_accuracy: 0.8455\n",
      "Epoch 40/100\n",
      "3198/3198 [==============================] - 1s 178us/step - loss: 0.2062 - categorical_accuracy: 0.9359 - val_loss: 0.4283 - val_categorical_accuracy: 0.8483\n",
      "Epoch 41/100\n",
      "3198/3198 [==============================] - 0s 152us/step - loss: 0.2007 - categorical_accuracy: 0.9409 - val_loss: 0.4280 - val_categorical_accuracy: 0.8511\n",
      "Epoch 42/100\n",
      "3198/3198 [==============================] - 0s 127us/step - loss: 0.1959 - categorical_accuracy: 0.9403 - val_loss: 0.4261 - val_categorical_accuracy: 0.8680\n",
      "Epoch 43/100\n",
      "3198/3198 [==============================] - 0s 130us/step - loss: 0.1979 - categorical_accuracy: 0.9412 - val_loss: 0.4907 - val_categorical_accuracy: 0.8258\n",
      "Epoch 44/100\n",
      "3198/3198 [==============================] - 0s 125us/step - loss: 0.2190 - categorical_accuracy: 0.9331 - val_loss: 0.4610 - val_categorical_accuracy: 0.8287\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198/3198 [==============================] - 0s 144us/step - loss: 0.2108 - categorical_accuracy: 0.9409 - val_loss: 0.3818 - val_categorical_accuracy: 0.8792\n",
      "Epoch 46/100\n",
      "3198/3198 [==============================] - 0s 134us/step - loss: 0.2017 - categorical_accuracy: 0.9434 - val_loss: 0.4095 - val_categorical_accuracy: 0.8652\n",
      "Epoch 47/100\n",
      "3198/3198 [==============================] - 0s 148us/step - loss: 0.2078 - categorical_accuracy: 0.9390 - val_loss: 0.4261 - val_categorical_accuracy: 0.8455\n",
      "Epoch 48/100\n",
      "3198/3198 [==============================] - 0s 131us/step - loss: 0.1953 - categorical_accuracy: 0.9418 - val_loss: 0.4219 - val_categorical_accuracy: 0.8567\n",
      "Epoch 49/100\n",
      "3198/3198 [==============================] - 0s 129us/step - loss: 0.2100 - categorical_accuracy: 0.9340 - val_loss: 0.4147 - val_categorical_accuracy: 0.8399\n",
      "Epoch 50/100\n",
      "3198/3198 [==============================] - 0s 141us/step - loss: 0.2100 - categorical_accuracy: 0.9406 - val_loss: 0.4052 - val_categorical_accuracy: 0.8511\n",
      "Epoch 51/100\n",
      "3198/3198 [==============================] - 0s 109us/step - loss: 0.2036 - categorical_accuracy: 0.9459 - val_loss: 0.4420 - val_categorical_accuracy: 0.8258\n",
      "Epoch 52/100\n",
      "3198/3198 [==============================] - 1s 160us/step - loss: 0.2007 - categorical_accuracy: 0.9422 - val_loss: 0.4268 - val_categorical_accuracy: 0.8455\n",
      "Epoch 53/100\n",
      "3198/3198 [==============================] - 0s 119us/step - loss: 0.2022 - categorical_accuracy: 0.9425 - val_loss: 0.4504 - val_categorical_accuracy: 0.8511\n",
      "Epoch 54/100\n",
      "3198/3198 [==============================] - 1s 164us/step - loss: 0.2042 - categorical_accuracy: 0.9365 - val_loss: 0.4003 - val_categorical_accuracy: 0.8624\n",
      "Epoch 55/100\n",
      "3198/3198 [==============================] - 0s 142us/step - loss: 0.2020 - categorical_accuracy: 0.9412 - val_loss: 0.3927 - val_categorical_accuracy: 0.8511\n",
      "Epoch 56/100\n",
      "3198/3198 [==============================] - 0s 116us/step - loss: 0.2022 - categorical_accuracy: 0.9393 - val_loss: 0.4405 - val_categorical_accuracy: 0.8483\n",
      "Epoch 57/100\n",
      "3198/3198 [==============================] - 0s 146us/step - loss: 0.1918 - categorical_accuracy: 0.9468 - val_loss: 0.4884 - val_categorical_accuracy: 0.8343\n",
      "Epoch 58/100\n",
      "3198/3198 [==============================] - 0s 124us/step - loss: 0.1966 - categorical_accuracy: 0.9478 - val_loss: 0.4040 - val_categorical_accuracy: 0.8624\n",
      "Epoch 59/100\n",
      "3198/3198 [==============================] - 0s 128us/step - loss: 0.1893 - categorical_accuracy: 0.9472 - val_loss: 0.3949 - val_categorical_accuracy: 0.8539\n",
      "Epoch 60/100\n",
      "3198/3198 [==============================] - 1s 182us/step - loss: 0.1995 - categorical_accuracy: 0.9487 - val_loss: 0.4250 - val_categorical_accuracy: 0.8511\n",
      "Epoch 61/100\n",
      "3198/3198 [==============================] - 0s 126us/step - loss: 0.2024 - categorical_accuracy: 0.9443 - val_loss: 0.4234 - val_categorical_accuracy: 0.8539\n",
      "Epoch 62/100\n",
      "3198/3198 [==============================] - 0s 145us/step - loss: 0.1939 - categorical_accuracy: 0.9481 - val_loss: 0.4372 - val_categorical_accuracy: 0.8483\n",
      "Epoch 63/100\n",
      "3198/3198 [==============================] - 0s 138us/step - loss: 0.1908 - categorical_accuracy: 0.9443 - val_loss: 0.4596 - val_categorical_accuracy: 0.8483\n",
      "Epoch 64/100\n",
      "3198/3198 [==============================] - 0s 131us/step - loss: 0.1956 - categorical_accuracy: 0.9472 - val_loss: 0.4464 - val_categorical_accuracy: 0.8680\n",
      "Epoch 65/100\n",
      "3198/3198 [==============================] - 1s 171us/step - loss: 0.1935 - categorical_accuracy: 0.9396 - val_loss: 0.4369 - val_categorical_accuracy: 0.8371\n",
      "Epoch 66/100\n",
      "3198/3198 [==============================] - 0s 125us/step - loss: 0.1886 - categorical_accuracy: 0.9484 - val_loss: 0.4403 - val_categorical_accuracy: 0.8624\n",
      "Epoch 67/100\n",
      "3198/3198 [==============================] - 0s 129us/step - loss: 0.1771 - categorical_accuracy: 0.9528 - val_loss: 0.4588 - val_categorical_accuracy: 0.8455\n",
      "Epoch 68/100\n",
      "3198/3198 [==============================] - 0s 152us/step - loss: 0.1930 - categorical_accuracy: 0.9481 - val_loss: 0.4145 - val_categorical_accuracy: 0.8427\n",
      "Epoch 69/100\n",
      "3198/3198 [==============================] - 1s 162us/step - loss: 0.1909 - categorical_accuracy: 0.9500 - val_loss: 0.4890 - val_categorical_accuracy: 0.8427\n",
      "Epoch 70/100\n",
      "3198/3198 [==============================] - 1s 171us/step - loss: 0.1862 - categorical_accuracy: 0.9534 - val_loss: 0.4161 - val_categorical_accuracy: 0.8652\n",
      "Epoch 71/100\n",
      "3198/3198 [==============================] - 1s 164us/step - loss: 0.1855 - categorical_accuracy: 0.9497 - val_loss: 0.4919 - val_categorical_accuracy: 0.8315\n",
      "Epoch 72/100\n",
      "3198/3198 [==============================] - 1s 164us/step - loss: 0.1830 - categorical_accuracy: 0.9503 - val_loss: 0.3874 - val_categorical_accuracy: 0.8680\n",
      "Epoch 73/100\n",
      "3198/3198 [==============================] - 0s 116us/step - loss: 0.1875 - categorical_accuracy: 0.9472 - val_loss: 0.4381 - val_categorical_accuracy: 0.8596\n",
      "Epoch 74/100\n",
      "3198/3198 [==============================] - 0s 131us/step - loss: 0.1842 - categorical_accuracy: 0.9481 - val_loss: 0.4640 - val_categorical_accuracy: 0.8399\n",
      "Epoch 75/100\n",
      "3198/3198 [==============================] - 1s 173us/step - loss: 0.1912 - categorical_accuracy: 0.9465 - val_loss: 0.4733 - val_categorical_accuracy: 0.8399\n",
      "Epoch 76/100\n",
      "3198/3198 [==============================] - 1s 157us/step - loss: 0.1846 - categorical_accuracy: 0.9515 - val_loss: 0.4301 - val_categorical_accuracy: 0.8624\n",
      "Epoch 77/100\n",
      "3198/3198 [==============================] - 0s 148us/step - loss: 0.1783 - categorical_accuracy: 0.9478 - val_loss: 0.4433 - val_categorical_accuracy: 0.8539\n",
      "Epoch 78/100\n",
      "3198/3198 [==============================] - 0s 131us/step - loss: 0.1969 - categorical_accuracy: 0.9493 - val_loss: 0.4381 - val_categorical_accuracy: 0.8596\n",
      "Epoch 79/100\n",
      "3198/3198 [==============================] - 0s 154us/step - loss: 0.1812 - categorical_accuracy: 0.9547 - val_loss: 0.4535 - val_categorical_accuracy: 0.8539\n",
      "Epoch 80/100\n",
      "3198/3198 [==============================] - 0s 133us/step - loss: 0.1859 - categorical_accuracy: 0.9547 - val_loss: 0.4697 - val_categorical_accuracy: 0.8539\n",
      "Epoch 81/100\n",
      "3198/3198 [==============================] - 1s 171us/step - loss: 0.1887 - categorical_accuracy: 0.9484 - val_loss: 0.4430 - val_categorical_accuracy: 0.8596\n",
      "Epoch 82/100\n",
      "3198/3198 [==============================] - 0s 150us/step - loss: 0.1863 - categorical_accuracy: 0.9497 - val_loss: 0.4437 - val_categorical_accuracy: 0.8511\n",
      "Epoch 83/100\n",
      "3198/3198 [==============================] - 0s 125us/step - loss: 0.1924 - categorical_accuracy: 0.9447 - val_loss: 0.4400 - val_categorical_accuracy: 0.8624\n",
      "Epoch 84/100\n",
      "3198/3198 [==============================] - 0s 140us/step - loss: 0.1869 - categorical_accuracy: 0.9506 - val_loss: 0.4092 - val_categorical_accuracy: 0.8624\n",
      "Epoch 85/100\n",
      "3198/3198 [==============================] - 0s 145us/step - loss: 0.1800 - categorical_accuracy: 0.9543 - val_loss: 0.4589 - val_categorical_accuracy: 0.8567\n",
      "Epoch 86/100\n",
      "3198/3198 [==============================] - 0s 127us/step - loss: 0.1749 - categorical_accuracy: 0.9528 - val_loss: 0.4834 - val_categorical_accuracy: 0.8399\n",
      "Epoch 87/100\n",
      "3198/3198 [==============================] - 0s 131us/step - loss: 0.1943 - categorical_accuracy: 0.9456 - val_loss: 0.4139 - val_categorical_accuracy: 0.8567\n",
      "Epoch 88/100\n",
      "3198/3198 [==============================] - 0s 142us/step - loss: 0.1929 - categorical_accuracy: 0.9465 - val_loss: 0.4931 - val_categorical_accuracy: 0.8287\n",
      "Epoch 89/100\n",
      "3198/3198 [==============================] - 1s 162us/step - loss: 0.1855 - categorical_accuracy: 0.9518 - val_loss: 0.4311 - val_categorical_accuracy: 0.8567\n",
      "Epoch 90/100\n",
      "3198/3198 [==============================] - 0s 153us/step - loss: 0.1736 - categorical_accuracy: 0.9581 - val_loss: 0.4682 - val_categorical_accuracy: 0.8567\n",
      "Epoch 91/100\n",
      "3198/3198 [==============================] - 0s 150us/step - loss: 0.1836 - categorical_accuracy: 0.9503 - val_loss: 0.4435 - val_categorical_accuracy: 0.8567\n",
      "Epoch 92/100\n",
      "3198/3198 [==============================] - 0s 134us/step - loss: 0.1977 - categorical_accuracy: 0.9434 - val_loss: 0.5209 - val_categorical_accuracy: 0.8371\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3198/3198 [==============================] - 0s 147us/step - loss: 0.1866 - categorical_accuracy: 0.9512 - val_loss: 0.4732 - val_categorical_accuracy: 0.8539\n",
      "Epoch 94/100\n",
      "3198/3198 [==============================] - 1s 170us/step - loss: 0.1778 - categorical_accuracy: 0.9550 - val_loss: 0.4607 - val_categorical_accuracy: 0.8315\n",
      "Epoch 95/100\n",
      "3198/3198 [==============================] - 0s 154us/step - loss: 0.1798 - categorical_accuracy: 0.9478 - val_loss: 0.5062 - val_categorical_accuracy: 0.8399\n",
      "Epoch 96/100\n",
      "3198/3198 [==============================] - 0s 132us/step - loss: 0.1781 - categorical_accuracy: 0.9522 - val_loss: 0.4359 - val_categorical_accuracy: 0.8455\n",
      "Epoch 97/100\n",
      "3198/3198 [==============================] - 0s 147us/step - loss: 0.1790 - categorical_accuracy: 0.9518 - val_loss: 0.4626 - val_categorical_accuracy: 0.8455\n",
      "Epoch 98/100\n",
      "3198/3198 [==============================] - 1s 162us/step - loss: 0.1769 - categorical_accuracy: 0.9556 - val_loss: 0.4555 - val_categorical_accuracy: 0.8399\n",
      "Epoch 99/100\n",
      "3198/3198 [==============================] - 1s 170us/step - loss: 0.1765 - categorical_accuracy: 0.9568 - val_loss: 0.3973 - val_categorical_accuracy: 0.8624\n",
      "Epoch 100/100\n",
      "3198/3198 [==============================] - 1s 164us/step - loss: 0.1594 - categorical_accuracy: 0.9587 - val_loss: 0.4380 - val_categorical_accuracy: 0.8539\n",
      "2022-11-09 02:56:46,325: INFO): Saving history...\n",
      "2022-11-09 02:56:46,326: INFO): Best CV:\n",
      "2022-11-09 02:56:46,326: INFO): epoch: 12\n",
      "2022-11-09 02:56:46,326: INFO): train:    0.923 (0.004)   val:   0.889 (0.004)\n",
      "2022-11-09 02:56:46,326: INFO): Test:\n",
      "2022-11-09 02:56:46,326: INFO): train:    0.920   val:   0.840\n",
      "2022-11-09 02:56:46,326: INFO): Resetting model weights from epoch with best cross-val score\n",
      "2022-11-09 02:56:46,973: INFO): TPR:    0.798  TNR:    0.848\n",
      "2022-11-09 02:56:46,976: INFO): Saving model weights\n",
      "2022-11-09 02:56:46,990: INFO): Making bayesian prediction on 356 samples\n",
      "2022-11-09 02:56:51,829: INFO): Done. Saving...\n",
      "2022-11-09 02:56:51,838: INFO): EOT, NCR\n"
     ]
    }
   ],
   "source": [
    "!python make_experiment.py --config config_files/rdkit_ae_zinc_bayesian.yaml --validation_mode 5cv_test --output_core experiments/rdkit_ae_zinc_bayesian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed112b37",
   "metadata": {},
   "source": [
    "### Mol2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python make_experiment.py --config config_files/mol2vec_zinc.yaml --validation_mode 5cv_test --output_core experiments/mol2vec_zinc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e6f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "845f938d",
   "metadata": {},
   "source": [
    "### GCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d09fe97",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python make_experiment.py --config config_files/gcnn_zinc.yaml --validation_mode 5cv_test --output_core experiments/gcnn_zinc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6e7260",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06aa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26da5e34",
   "metadata": {},
   "source": [
    "### Run Prediction (Random input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea208c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:30: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:167: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:284: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1101: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1127: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1362: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1602: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1738: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "/home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:32: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from models import make_ae_model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c6b4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(Path('config_files/rdkit_ae_zinc_bayesian.yaml').read_text())\n",
    "config = config['model_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f5b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = 199\n",
    "output_shape = (1,2)\n",
    "len(output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "380a17de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/amna/anaconda3/envs/bayesian-druglikeness/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-09 02:56:58.343944: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-11-09 02:56:58.355399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2419205000 Hz\n",
      "2022-11-09 02:56:58.358546: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0xa52790 executing computations on platform Host. Devices:\n",
      "2022-11-09 02:56:58.358648: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.26661932, 0.7333806 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, metric = make_ae_model(input_shape, output_shape, config)\n",
    "inp = np.random.rand(1,199)\n",
    "proba = model.predict(inp)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edabbd2",
   "metadata": {},
   "source": [
    "### Run prediction on test SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/vectorize.py --output_core smiles --descriptor rdkit  data/smiles.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b0d9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "from data_preprocess import _normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99d5b3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 208)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name= 'data/smiles.npz'\n",
    "with gzip.open(name, 'rb') as f:\n",
    "      data = np.load(f)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c6963b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = ('data/zinc15_nondrugs_sample_rdkit_mu.npz', 'data/zinc15_nondrugs_sample_rdkit_std.npz', 'data/zinc15_nondrugs_sample_rdkit_idx.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d6163af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = _normalize(data, idx, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf826bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.77059305e-01 -6.09888778e-01 -1.28502295e+00 -9.14554061e-01\n",
      "  -6.74518269e-01 -1.42050523e-01 -7.34462755e-01 -4.41028515e-01\n",
      "   2.18092164e+00  5.13150440e+00  1.23310758e+01  1.16785026e+01\n",
      "   1.13491346e+01  1.07108179e+01  1.10717178e+01  1.02150897e+01\n",
      "   9.96530675e+00  8.52736977e+00  7.62531964e+00  6.24557226e+00\n",
      "   5.78379013e+00  4.54681166e+00  1.54765482e+01  8.66264957e+00\n",
      "  -2.00300673e-02  8.24696218e+00 -3.88745165e-02 -1.92410480e-01\n",
      "   5.19650366e-02  1.95641488e+00 -1.22491897e+00  3.50929011e+00\n",
      "   2.73584103e+00  1.12454087e+01 -3.41752572e+00 -3.76038605e+00\n",
      "  -3.81072245e+00  1.74378991e+00 -5.13453133e+00  1.10990849e+01\n",
      "   1.05783756e+01  1.59590862e+06  1.53981518e+01  1.75492177e+01\n",
      "   1.79387084e+01  1.11463137e+01  1.23353339e+00 -3.70513917e-01\n",
      "   1.23353339e+00 -3.81175951e-01 -7.69704036e-01 -3.66796881e-01\n",
      "  -5.71172782e-01  3.31340425e-01 -5.46587112e+00  1.03774303e+01\n",
      "   1.12316560e+01  2.12921530e+01  1.32661728e+01 -3.88838957e-01\n",
      "   4.44331940e-01  1.60073845e-01 -3.97901303e-01 -1.03222582e+00\n",
      "  -1.17370668e+00  7.92581886e+00  1.82325821e+01  1.13084593e+01\n",
      "   1.11880506e+01 -3.20059973e-01  8.51707865e-01  5.36364924e-01\n",
      "   1.27720897e+01  1.43133294e+01  7.31777335e+00 -7.51166369e-01\n",
      "   1.19647727e+01 -8.44673624e-01 -6.13049194e-01  7.84153056e+00\n",
      "  -1.01644285e+00 -5.71005621e-01 -5.28084409e-01  2.95069568e+00\n",
      "   4.87299325e+00 -1.87394655e-01 -2.57402040e-01 -9.59972549e-01\n",
      "   6.86317696e+00  3.28686263e+00 -2.19639182e-01  6.84136439e+00\n",
      "   7.63724689e+00  1.01463561e+01  1.63905962e+00 -7.14775114e-01\n",
      "  -7.99413795e-01  1.35227943e+01 -9.09855264e-01 -6.35854820e-01\n",
      "  -7.41462600e-01  9.16062673e+00  6.70949328e+00  7.10846447e-01\n",
      "   6.11709889e+00 -5.51120548e-01 -3.97323669e-01 -6.84855241e-01\n",
      "   1.70458690e+01 -8.93768961e-01 -5.96258968e-01  1.22006542e+01\n",
      "   7.02196378e+00  1.30004634e+01 -6.09992895e+00 -2.69569412e+00\n",
      "  -1.18537815e+00  1.75369154e+00 -1.75722374e-01 -1.34501810e-01\n",
      "   6.04760168e+00  6.51953842e+00 -1.44006462e-01 -1.17706180e-01\n",
      "  -8.62013551e-01 -3.53042294e-01 -1.98518345e-01 -1.80111808e-01\n",
      "  -1.80111808e-01  1.19158767e+01  1.20493541e+01 -1.33282515e-01\n",
      "  -8.28524376e-02 -1.81537925e-01 -1.32953282e+00  1.17668517e+01\n",
      "   1.93991157e+01 -4.37551031e-02 -2.55957894e-01 -4.12716160e-01\n",
      "  -3.53042294e-01 -1.41619767e-02 -6.37202176e-02 -6.34553080e-02\n",
      "  -2.10685346e-01 -2.13645358e-01  1.12507131e+01 -1.25371913e-01\n",
      "  -7.63337882e-01 -6.88698257e-01 -6.65658866e-02 -5.49262664e-02\n",
      "  -3.98119013e-01 -6.07713879e-01 -4.91127311e-02 -3.16798541e-02\n",
      "  -3.28570337e-01 -8.07608109e-01 -2.44115749e-01 -7.09809202e-02\n",
      "  -5.84641516e-01 -1.30926683e-01 -1.79325856e-01 -2.69325529e-01\n",
      "  -1.74583406e-01 -2.58619497e-01 -2.46578700e-01 -2.00300683e-02\n",
      "  -8.05027484e-02 -4.55563423e-01 -2.26844229e-01 -2.11615191e-01\n",
      "  -2.12056585e-01 -1.93230521e-01 -1.52462152e-01 -2.00300683e-02\n",
      "  -1.16695700e-01 -7.37804059e-02 -4.84391599e-01 -1.56807711e-01\n",
      "  -1.55515897e-01 -1.96409467e-02 -1.96409467e-02 -3.81767935e-01\n",
      "  -2.79622943e-01 -1.50879283e-01 -3.90633601e-01 -2.84067713e-01\n",
      "  -3.55400609e-01 -3.12234224e-01 -1.76160568e-01 -7.09809193e-02\n",
      "  -1.10411212e-01 -2.74849998e-01 -1.41619767e-02 -2.84706455e-01\n",
      "   1.93659110e+00 -3.04833667e-01 -3.49426450e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f124af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8974c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613389da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/smiles.txt','r') as firstfile, open('data/smiles2.txt','w') as secondfile:\n",
    "    next(firstfile)\n",
    "    for line in firstfile:\n",
    "        secondfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f70b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bayesian-druglikeness] *",
   "language": "python",
   "name": "conda-env-bayesian-druglikeness-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
